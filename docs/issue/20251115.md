# **Issue 1 â€” Implement Multi-Token Activation Patching** âœ… **å®Œäº†**

### **Description**

Current activation patching only generates **1 token** (next-token logits).

This prevents measuring stylistic change, sentiment patterns, politeness, or multi-step causal influence.

### **To-Do**

* [X] Modify `ActivationPatcher` to support multi-token generation
* [X] Keep patch active across all generation steps
* [X] Add an option to patch only specific token positions (windowed patching)
* [X] Implement patching strength schedules (e.g., decaying Î±)
* [X] Add tests verifying consistency across multiple generations

### **å®Ÿè£…å†…å®¹**

**`src/models/activation_patching.py`ã®å…¨é¢åˆ·æ–°**:
- `generate_with_patching`ãŒ`HookedTransformer.generate`ã‚’ä½¿ç”¨ã—ã¦multi-tokenç”Ÿæˆã«å¯¾å¿œ
- `_generate_tokens_with_patch`ã§å…¨ç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—ã§hookã‚’åŠ¹ã‹ã›ã‚‹ã‚ˆã†ã«å®Ÿè£…ï¼ˆç”Ÿæˆä¸­ã®ç¶™ç¶šãƒ‘ãƒƒãƒï¼‰
- `_resolve_patch_positions`ã§ãƒ‘ãƒƒãƒå¯¾è±¡ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æŒ‡å®šãƒ»æ˜ç¤ºä½ç½®æŒ‡å®šãƒ»æ–°è¦ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿æŒ‡å®šã«å¯¾å¿œ
- Î±ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ`alpha_schedule`ï¼‰ã¨æ¸›è¡°ï¼ˆ`alpha_decay_rate`ï¼‰ã‚’å®Ÿè£…ï¼ˆ`_build_alpha_schedule`ï¼‰
- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç”Ÿæˆã‚‚multi-tokenåŒ–ï¼ˆ`_generate_text`ãŒ`HookedTransformer.generate`ã‚’ä½¿ç”¨ï¼‰

**CLIã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ **:

- `--max-new-tokens`: ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- `--patch-window`: ãƒ‘ãƒƒãƒå¯¾è±¡ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
- `--patch-positions`: æ˜ç¤ºçš„ãªãƒ‘ãƒƒãƒä½ç½®æŒ‡å®šï¼ˆè² ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾å¿œï¼‰
- `--patch-new-only`: æ–°è¦ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ãƒ‘ãƒƒãƒ
- `--alpha-schedule`: ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®Î±å€¤ãƒªã‚¹ãƒˆ
- `--alpha-decay-rate`: Î±ã®æ¸›è¡°ç‡

**ãƒ†ã‚¹ãƒˆè¿½åŠ **:

- `tests/test_activation_patching.py`: multi-tokenç”Ÿæˆã¨ãƒ˜ãƒ«ãƒ‘é–¢æ•°ã®æ¤œè¨¼

### **Why**

Without multi-token generation, we cannot test causal influence of emotion vectors on style.

Codex review found earlier claims unsupported because of this limitation.

### **Paths**

<pre class="overflow-visible!" data-start="1209" data-end="1290"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/models/activation_patching.py âœ…
src/models/activation_patching_sweep.py âœ…
tests/test_activation_patching.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 2 â€” Replace Heuristic Sentiment/Politeness Metrics** âœ… **å®Œäº†**

### **Description**

Layerâ€“alpha sweeps currently rely on  **keyword-based heuristics** .

Need transformer-based metrics for real sentiment/politeness evaluation.

### **To-Do**

* [X] Introduce a RoBERTa / DistilBERT sentiment classifier
* [X] Integrate â€œStanford Politenessâ€ model
* [X] Add emotion classification via GoEmotions
* [X] Store all metrics in MLflow per-prompt
* [X] Build visualization scripts (heatmaps, violin plots)

### **å®Ÿè£…å†…å®¹**

**`src/analysis/sentiment_eval.py`ã®å¤§å¹…æ‹¡å¼µ**:

- `SentimentEvaluator`ã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ 
- `TransformerSequenceClassifier`ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã§HuggingFaceåˆ†é¡å™¨ã‚’ãƒ©ãƒƒãƒ—
- **CardiffNLP sentiment**: `cardiffnlp/twitter-roberta-base-sentiment-latest`ã‚’ä½¿ç”¨
- **Stanford Politeness**: `michellejieli/Stanford_politeness_roberta`ã‚’ä½¿ç”¨
- **GoEmotions**: `bhadresh-savani/roberta-base-go-emotions`ã‚’ä½¿ç”¨
- `evaluate_text_metrics`ã§ä¸€æ‹¬è©•ä¾¡ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«æ—§ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
- `HookedTransformer`ã®èª­ã¿è¾¼ã¿ã‚’ä»»æ„åŒ–ï¼ˆ`load_generation_model=False`ã§è©•ä¾¡ã®ã¿å®Ÿè¡Œå¯èƒ½ï¼‰

**`src/models/activation_patching_sweep.py`ã®åˆ·æ–°**:
- ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æŒ‡æ¨™ï¼ˆ`count_emotion_keywords`, `calculate_politeness_score`, `calculate_sentiment_score`ï¼‰ã‚’å»ƒæ­¢
- `SentimentEvaluator`ã«ã‚ˆã‚‹RoBERTaç³»ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨
- baseline/patchä¸¡æ–¹ã§ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒæŒ‡æ¨™ã‚’ä¿å­˜
- MLflowã«flattenã—ã¦ãƒ­ã‚°åŒ–ï¼ˆãƒã‚¹ãƒˆè¾æ›¸å¯¾å¿œã€`_flatten_metrics`ï¼‰
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆ/å·®åˆ†è¨ˆç®—ã‚‚ãƒã‚¹ãƒˆè¾æ›¸å¯¾å¿œã«åˆ·æ–°ï¼ˆ`_mean_nested_metrics`, `_subtract_metric_dicts`ï¼‰

**`src/models/activation_patching_random.py`ã®æ›´æ–°**:
- æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©•ä¾¡ï¼ˆ`SentimentEvaluator`ï¼‰ã‚’åˆ©ç”¨ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´

**`src/visualization/patching_heatmaps.py`ã®æ›´æ–°**:
- ãƒã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹æ§‹é€ ã«å¯¾å¿œï¼ˆ`_get_metric_value`ã§ãƒ‘ã‚¹æŒ‡å®šï¼‰
- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆï¼ˆå±¤Ã—Î±ã®å¯è¦–åŒ–ã€`create_heatmap`ï¼‰
- ãƒã‚¤ã‚ªãƒªãƒ³ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆï¼ˆåˆ†å¸ƒã®æ¯”è¼ƒã€`create_violin`ï¼‰

**ãƒ†ã‚¹ãƒˆè¿½åŠ **:
- `tests/test_sentiment_eval.py`: `SentimentEvaluator`ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª

### **Why**

Heuristic metrics were responsible for near-zero deltas; real effects may be detectable with better scorers.

### **Paths**

<pre class="overflow-visible!" data-start="1940" data-end="2018"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex.items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/analysis/sentiment_eval.py âœ…
src/models/activation_patching_sweep.py âœ…
src/models/activation_patching_random.py âœ…
src/visualization/patching_heatmaps.py âœ…
tests/test_sentiment_eval.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 3 â€” Improve Random Control Experiments** âœ… **å®Œäº†**

### **Description**

The random vector baseline is incomplete: no aggregated metrics, no statistical tests, and no saved CSV/plots.

### **To-Do**

* [X] Generate â‰¥100 random vectors per emotion (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’100ã«å¤‰æ›´)
* [X] Compare effect size (Cohenâ€™s d) with emotion vectors
* [X] Run permutation tests / bootstrap confidence intervals
* [X] Save results as CSV and visualizations (heatmaps / violin via `random_vs_emotion_effect.py`)
* [X] Add MLflow logging (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ãƒ©ã‚°ã§æœ‰åŠ¹åŒ–)

### **å®Ÿè£…å†…å®¹**

**`src/models/activation_patching_random.py`**:
- MLflowãƒ­ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼ˆ`--mlflow`ãƒ•ãƒ©ã‚°ã§æœ‰åŠ¹åŒ–ï¼‰
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ™ã‚¯ãƒˆãƒ«æ•°ã‚’100ã«è¨­å®š
- æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©•ä¾¡ï¼ˆ`SentimentEvaluator`ï¼‰ã‚’åˆ©ç”¨

**`src/analysis/random_vs_emotion_effect.py`ã®å¤§å¹…æ‹¡å¼µ**:
- ãƒã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹å¯¾å¿œã®åŠ¹æœé‡è¨ˆç®—ï¼ˆCohen's dï¼‰
- ãƒ‘ãƒ¼ãƒŸãƒ¥ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¤œå®šï¼ˆ`_permutation_pvalue`ï¼‰
- ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ä¿¡é ¼åŒºé–“ï¼ˆ`_bootstrap_ci`ï¼‰
- CSVå‡ºåŠ›ï¼ˆ`--output_csv`, `--distributions_csv`ï¼‰
- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆï¼ˆåŠ¹æœé‡ã®å¯è¦–åŒ–ã€`create_heatmaps`ï¼‰
- ãƒã‚¤ã‚ªãƒªãƒ³ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆï¼ˆåˆ†å¸ƒã®æ¯”è¼ƒã€`create_violin_plots`ï¼‰

### **Why**

Codex review: â€œNo evidence random vectors have no effect.â€

To support claims, statistical testing is required.

### **Paths**

<pre class="overflow-visible!" data-start="2610" data-end="2699"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/models/activation_patching_random.py âœ…
src/analysis/random_vs_emotion_effect.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 4 â€” Add Real Evaluation for Real-World Patching** âœ… **å®Œäº†**

### **Description**

Real-world patching currently logs only the first next-token prediction.

Need full text generation and evaluation.

### **To-Do**

* [X] Use multi-token patching (Issue 1) âœ… Issue 1å®Œäº†ã«ã‚ˆã‚Šåˆ©ç”¨å¯èƒ½
* [X] Add sentiment/politeness/fluency scoring âœ… Issue 2å®Œäº†ã«ã‚ˆã‚Šåˆ©ç”¨å¯èƒ½
* [X] Create real-world evaluation datasets (SNS, business email, reviews) âœ… `data/real_world_samples.json`ã«å­˜åœ¨
* [X] Implement evaluation script for real-world prompts (`src/analysis/real_world_patching.py`)
* [X] Visualize pre/post patching differencesï¼ˆ`src/visualization/real_world_plots.py`: violin/barã€CSVå‡ºåŠ›ï¼‰
* [X] Add statistical testsï¼ˆãƒšã‚¢tæ¤œå®šã®mean_diff/t/pã‚’å‡ºåŠ›ï¼‰

### **å®Ÿè£…å†…å®¹**

**`src/analysis/real_world_patching.py`**:
- multi-token patchingã¨TransformeræŒ‡æ¨™ã‚’ç”¨ã„ãŸå®Ÿä¸–ç•Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‹å„emotion/Î±ã§ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜
- `ActivationPatcher`ã¨`SentimentEvaluator`ã‚’ä½¿ç”¨

**`src/visualization/real_world_plots.py`**:
- å‰å¾Œæ¯”è¼ƒã®ãƒã‚¤ã‚ªãƒªãƒ³/ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ
- ãƒšã‚¢tæ¤œå®šï¼ˆmean_diff/t/pï¼‰ã‚’å‡ºåŠ›
- ãƒ•ãƒ©ãƒƒãƒˆCSVå‡ºåŠ›ï¼ˆ`real_world_metrics.csv`ï¼‰

### **Why**

Current stored artifact `patching_realworld.pkl` is not a valid evaluation.

Codex: â€œGeneralization claims unsupported.â€

### **Paths**

<pre class="overflow-visible!" data-start="3315" data-end="3391"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>data/real_world_samples.json âœ…
src/analysis/real_world_patching.py âœ…
src/visualization/real_world_plots.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 5 â€” Strengthen Head Patching Mechanism** âœ… **å®Œäº†**

### **Description**

Head patching currently:

* uses only the **first emotion prompt**
* patches **v-only**
* sentiment gain is small (+0.0149)

### **To-Do**

* [X] Collect head outputs from *all* emotion prompts
* [X] Support full head output patching (pattern + v)
* [X] Add option to patch multiple heads simultaneously
* [X] Implement â€œuse_attn_result=Trueâ€ workaroundï¼ˆ`patch_mode=result`ã§hook_resultã‚’ä¸Šæ›¸ãã€use_attn_result=Trueèµ·å‹•ã«å¯¾å¿œï¼‰
* [X] Add multi-token generation for head-level patchingï¼ˆgenerate APIåˆ©ç”¨ï¼‰

### **Why**

Codex: earlier claims about head influence are overstated.

### **å®Ÿè£…å†…å®¹**

**`src/models/head_patching.py`ã®å¤§å¹…æ‹¡å¼µ**:
- æ„Ÿæƒ…ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨ä½“ã‹ã‚‰`pattern`/`V`/`head_output`ã‚’å¹³å‡ã—ã¦ä½¿ç”¨
- `patch_mode`ã«`v_only`/`pattern_v`/`result`ã‚’è¿½åŠ 
- `use_attn_result=True`èµ·å‹•ã§`hook_result`ã«ã‚ˆã‚‹ç›´æ¥ãƒ‘ãƒƒãƒå¯¾å¿œ
- `generate` APIã§ãƒãƒ«ãƒãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã«å¯¾å¿œ
- è¤‡æ•°headåŒæ™‚ãƒ‘ãƒƒãƒã«å¯¾å¿œ

### **Paths**

<pre class="overflow-visible!" data-start="3975" data-end="4069"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/models/head_patching.py âœ…
src/models/head_ablation.py âœ…
src/analysis/head_screening.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 6 â€” Add MLP Unit Analysis (Neuron-Level Study)** âœ… **å®Œäº†**

### **Description**

MLP neuron contributions are currently untested.

### **To-Do**

* [x] Implement neuron-level ablation (`src/models/neuron_ablation.py`)
* [x] Add neuron lens inspection (`src/analysis/neuron_saliency.py`)
* [x] Analyze OV/QK circuit contributions âœ… Epic Issueã§å®Ÿè£…å®Œäº†
* [x] Aggregate neuron saliency per layer
* [x] Document circuits responsible for emotion amplification âœ… `circuit_report.py`ã§å®Ÿè£…

### **å®Ÿè£…å†…å®¹**

**`src/models/neuron_ablation.py`**:
- ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å˜ä½ã®ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã‚’å®Ÿè£…
- æŒ‡å®šãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ã‚¼ãƒ­ã‚¢ã‚¦ãƒˆã—ã¦ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®å¤‰åŒ–ã‚’è¦³å¯Ÿ

**`src/analysis/neuron_saliency.py`**:
- W_outÃ—emotionãƒ™ã‚¯ãƒˆãƒ«ã§ã‚µãƒªã‚¨ãƒ³ã‚·ãƒ¼ä¸Šä½ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç®—å‡º
- å±¤ã”ã¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚µãƒªã‚¨ãƒ³ã‚·ãƒ¼ã‚’é›†ç´„

**Epic Issue: OV/QK Circuit Analysisï¼ˆ2024å¹´11æœˆå®Œäº†ï¼‰**:
- `src/analysis/circuit_ov_qk.py`: OV/QKå›è·¯è§£æãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆTransformerLensæ–°ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å¯¾å¿œã€use_attn_result=Trueï¼‰
- `src/analysis/circuit_experiments.py`: OV/QKå›è·¯å®Ÿé¨“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆOV ablationã€QK routing patchingã€çµ±åˆå®Ÿé¨“ï¼‰
- `src/analysis/circuit_report.py`: OV/QKå›è·¯è§£æçµæœã®å¯è¦–åŒ–ã¨ã‚µãƒãƒªãƒ¼ç”Ÿæˆï¼ˆQK routing heatmapã€head-importance heatmapã€circuit_summary.md/jsonï¼‰

### **Why**

Emotion circuits rarely live only in attention heads; ignoring MLP units limits interpretability quality.

### **Paths**

<pre class="overflow-visible!" data-start="4580" data-end="4613"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/models/neuron_ablation.py âœ…
src/analysis/neuron_saliency.py âœ…
src/analysis/circuit_ov_qk.py âœ…
src/analysis/circuit_experiments.py âœ…
src/analysis/circuit_report.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 7 â€” Cross-Model Patching Using Alignment Maps** âœ… **å®Œäº†**

### **Description**

Subspace alignment showed models share near-identical emotion structure.

We should test whether aligned emotion vectors transfer across models.

### **To-Do**

* [x] Use `model_alignment.py` linear maps to transfer vectors
* [x] Patch GPT-2 using Pythia emotion vectors (and vice versa)
* [x] Measure changes in logits /_generated texts
* [x] Add cross-model sweep comparisons
* [ ] Visualize similarities & deltasï¼ˆå¯è¦–åŒ–ã¯æœªå®Ÿè£…ï¼‰

### **å®Ÿè£…å†…å®¹**

**`src/analysis/cross_model_patching.py`**:
- `model_alignment.py`ã®ç·šå½¢å†™åƒã‚’èª­ã¿è¾¼ã¿ã€æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ç©ºé–“ã¸è»¢é€
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã§ãƒ‘ãƒƒãƒãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã€TransformeræŒ‡æ¨™ã‚’åé›†
- CLIã§`--alignment`, `--src-vectors`, `--target-model`ãªã©ã‚’æŒ‡å®šå¯èƒ½
- Multi-tokenç”Ÿæˆã¨Transformerãƒ™ãƒ¼ã‚¹è©•ä¾¡ã«å¯¾å¿œ

### **Why**

This would produce the first causal cross-model interpretability evidence.

### **Paths**

<pre class="overflow-visible!" data-start="5227" data-end="5300"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/analysis/cross_model_patching.py âœ…
src/analysis/model_alignment.py âœ…
src/models/activation_patching.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 8 â€” Fix Head Screening Interpretation** â³ **æœªå®Ÿæ–½**

### **Description**

Current paper overstates â€œLayer 0 dominance.â€

Actual Î”attn rankings show larger effects in Layers 3â€“11.

### **To-Do**

* [ ] Re-analyze Î”attn ranking
* [ ] Add layer-wise summary plots
* [ ] Update documentation
* [ ] Add metrics to MLflow

### **å®Ÿè£…çŠ¶æ…‹**

- ãƒ˜ãƒƒãƒ‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å†è§£æã¨å¯è¦–åŒ–ã¯æœªå®Ÿæ–½
- `MLflow`ãƒ­ã‚®ãƒ³ã‚°æ‹¡å¼µï¼ˆ`log_nested_metrics`, `set_run_tags`ï¼‰ã‚’åˆ©ç”¨å¯èƒ½ã«ãªã£ãŸãŸã‚ã€ä»Šå¾Œã®å†èµ°æ™‚ã«è¨ˆæ¸¬äºˆå®š
- `head_screening.py`ã«MLflowãƒ­ã‚°æ¥ç¶šã¯æœªå®Ÿè£…

### **Why**

Codex: head_scores_gpt2.json contradicts the narrative.

### **Paths**

<pre class="overflow-visible!" data-start="5711" data-end="5798"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>results/baseline/alignment/head_scores_gpt2.json
src/analysis/head_screening.py
</span></span></code></div></div></pre>

---

# **Issue 9 â€” Expand MLflow Logging** ğŸ”„ **éƒ¨åˆ†å®Œäº†**

### **Description**

MLflow only logs coarse metrics (file size / runtime).

Need rich experiment tracking.

### **To-Do**

* [x] Log sentiment/politeness per promptï¼ˆ`log_nested_metrics`ã§å¯¾å¿œå¯èƒ½ï¼‰
* [ ] Log head-level metricsï¼ˆæœªæ¥ç¶šï¼‰
* [x] Log random-control effect sizesï¼ˆ`activation_patching_random.py`ã§MLflowã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ æ¸ˆã¿ï¼‰
* [ ] Log sweep resultsï¼ˆæœªæ¥ç¶šï¼‰
* [x] Add run tags for dataset profile / model / layersï¼ˆ`set_run_tags`ã§å¯¾å¿œå¯èƒ½ï¼‰

### **å®Ÿè£…å†…å®¹**

**`src/utils/mlflow_utils.py`ã®æ‹¡å¼µ**:
- `log_nested_metrics`: ãƒã‚¹ãƒˆè¾æ›¸ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’flattenã—ã¦ãƒ­ã‚°åŒ–
- `set_run_tags`: å®Ÿè¡Œã‚¿ã‚°ï¼ˆdataset profileã€modelã€layersãªã©ï¼‰ã‚’è¨­å®š

**æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã®åˆ©ç”¨çŠ¶æ³**:
- `activation_patching_random.py`: MLflowã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ æ¸ˆã¿ âœ…
- `activation_patching_sweep.py`: ãƒã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹å¯¾å¿œæ¸ˆã¿ï¼ˆMLflowãƒ­ã‚°ã¯æœªæ¥ç¶šï¼‰
- `head_screening.py`: MLflowãƒ­ã‚°æœªæ¥ç¶š

### **Why**

Improved reproducibility and interpretability research hygieneã€‚

### **Paths**

<pre class="overflow-visible!" data-start="6257" data-end="6290"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>src/utils/mlflow_utils.py âœ…
src/models/activation_patching_random.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 10 â€” Add CI Pipeline for â€œPaper vs Code Consistency Checkâ€** âœ… **å®Œäº†**

### **Description**

The Codex audit was highly valuable.

We can automate this on every pull request.

### **To-Do**

* [x] Write a script that checks:
  * missing artifacts
  * mismatch in documented numbers
  * mismatch in CLI parameters
* [x] Run through GitHub Actions
* [x] Fail build if inconsistency is detected (non-zero exit)

### **å®Ÿè£…å†…å®¹**

**`scripts/consistency_check.py`**:
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¡Œæ•°ã®ãƒã‚§ãƒƒã‚¯
- ä¸»è¦æˆæœç‰©ã®æœ‰ç„¡ãƒã‚§ãƒƒã‚¯
- ä¸»è¦CLIãƒ•ãƒ©ã‚°ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ

**`.github/workflows/code_paper_consistency.yml`**:
- PR/Pushæ™‚ã«è‡ªå‹•å®Ÿè¡Œ
- å¤±æ•—æ™‚ã¯éã‚¼ãƒ­çµ‚äº†ã§CIã‚’å¤±æ•—ã•ã›ã‚‹

### **Why**

Ensures that future papers / reports stay aligned with actual code.

### **Paths**

<pre class="overflow-visible!" data-start="6793" data-end="6886"><div class="contain-inline-size rounded-2xl relative bg-token-sidebar-surface-primary"><div class="sticky top-9"><div class="absolute end-0 bottom-0 flex h-9 items-center pe-2"><div class="bg-token-bg-elevated-secondary text-token-text-secondary flex items-center gap-4 rounded-sm px-2 font-sans text-xs"></div></div></div><div class="overflow-y-auto p-4" dir="ltr"><code class="whitespace-pre!"><span><span>.github/workflows/code_paper_consistency.yml âœ…
scripts/consistency_check.py âœ…
</span></span></code></div></div></pre>

---

# **Issue 11 â€” Improve Documentation & Appendices** â³ **æœªç€æ‰‹**

### **Description**

The original paper over-claimed several points.

Documentation should reflect limitations and constraints.

### **To-Do**

* [ ] Add â€œKnown Limitationsâ€ section
* [ ] Document that activation patching is one-step
* [ ] Document heuristic nature of sweep metrics
* [ ] Add reproducibility checklist
* [ ] Update README diagrams

### **å®Ÿè£…çŠ¶æ…‹**

- æœªç€æ‰‹ï¼ˆrev2.mdã§ä¸€éƒ¨è¨€åŠã‚ã‚Šã ãŒã€çµ±åˆã•ã‚ŒãŸæ—¢çŸ¥ã®åˆ¶ç´„ãƒ»ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã¯æœªè¿½åŠ ï¼‰
- READMEã‚„implementation_plan.mdã¸ã®ã€ŒKnown Limitationsã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ãŒå¿…è¦
- å†ç¾æ€§ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ä½œæˆãŒå¿…è¦

### **Why**

Improves reliability, transparency, and peer-review readiness.
