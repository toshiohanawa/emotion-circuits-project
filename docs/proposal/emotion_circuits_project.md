# emotion_circuits_project

# ***軽量LLMを用いた「感情表現回路」探索プロジェクト設計書（完全版）***

# 0. プロジェクト概要

## 0.1 背景

大規模言語モデル（LLM）は、人間のような「感謝」「怒り」「謝罪」などの感情・社会的表現を自然に生成する。しかし、**これらの感情がモデル内部でどのように表現されているのか**（どの層・どの方向・どの回路が担当しているか）については未解明である。

本プロジェクトでは、**軽量なオープンソース LLM を複数モデル使用し**,

- 感情（gratitude, anger, apology など）について
- 内部表現（residual stream / attention head / MLP unit）を解析し
- モデル間で共通性があるかを検証する

というパイロット研究を行う。

特に、**複数モデル間で感情方向が共通するか**は新規性の高いテーマである。

---

# 1. 目標とスコープ

## 1.1 長期的な最終目標

1. 各感情の内部表現（direction / subspace / head 特性）を特定する
2. 複数 LLM に共通する「感情回路」を発見する
3. Activation patching により、感情方向の操作が出力に与える因果的影響を調べる
4. 最終的には、感情理解を含む「社会的振る舞い」のメカニズム解明へつなげる

## 1.2 本プロジェクト（パイロット）のゴール

- 感謝・怒り・謝罪の 3 感情で
    - 感情方向ベクトルを抽出
    - モデル間類似度を評価
    - activation patching で出力トーン変化の確認
- 次のステップ（本格研究）に進む価値があるかを判断する

---

# 2. 使用ツール・モデル

## 2.1 ライブラリ

- Python
- PyTorch
- TransformerLens
- HuggingFace Transformers
- NumPy / pandas
- matplotlib / plotly

## 2.2 対象モデル（軽量）

小型で高速なモデル：

- GPT-2 small（124M）
- Pythia-70M / 160M
- DistilGPT-2
- （余裕があれば）TinyLlama / Llama オープンモデルの小型版

最初は **2モデル（GPT-2 / Pythia）** から開始するのが筋が良い。

---

# 3. 研究クエスチョン（RQ）

### **RQ1**：

感謝・怒り・謝罪などの感情は、層ごとに安定した方向ベクトルとして現れるか？

### **RQ2**：

異なる LLM 間で、同じ感情方向はどれくらい似ているか？

### **RQ3**：

感情方向を操作（増幅・抑制）すると、出力トーンは変化するか？

### **RQ4（余裕があれば）**：

特定の attention head や MLP unit が感情を強く担っているか？

---

# 4. 全体フェーズ設計（完全版）

---

# ⭐ **フェーズ0：環境構築（1〜2日）**

## 目的

実験を実行可能な環境を整える。

## 作業内容

- Python 仮想環境構築（uv / conda / venv）
- TransformerLens × Transformers × PyTorch セットアップ
- GPT-2 small で内部活性の hook が取れることを確認
- GitHub にリポジトリ作成

### 推奨ディレクトリ

```
emotion_circuits_pilot/
  ├─ README.md
  ├─ data/
  ├─ notebooks/
  ├─ src/
  └─ docs/

```

---

# **フェーズ1：感情プロンプトデータ作成（2〜3日）**

## 目的

感謝・怒り・謝罪（＋中立）の短文データセットを作成する。

## 感情カテゴリ

- Gratitude（感謝）
- Anger（怒り）
- Apology（謝罪）
- Neutral（中立）

## 作業内容

- 1カテゴリ 50〜200文（日本語＋英語）
- JSONL 形式で保存
- バリエーションを入れる（丁寧・砕けた・直接的・暗示的表現など）

### データ形式例

```json
{
  "text": "本当にありがとうございます。",
  "emotion": "gratitude",
  "lang": "ja"
}

```

---

# **フェーズ2：内部活性の抽出（1〜2週間）**

## 目的

すべての入力文に対して、モデルの **各層の residual stream（hidden states）** を保存する。

## 作業内容

### 2.1 モデルA（例：GPT-2 small）で

- 入力文をトークナイズ
- TransformerLens を使って
    - 各層の residual stream
    - 各層の MLP 出力
    - attention 先
        
        を hook で取得
        
- 出力を npy / pickle で保存

### 2.2 モデルB（例：Pythia-70M）でも同様に実行

### 保存する情報

- residual stream（各層）
- token position
- emotion label

---

# **フェーズ3：感情方向ベクトルの抽出・可視化（1〜2週間）**

## 目的

感情 vs 中立の差分から感情方向を抽出し、モデル内・モデル間で比較する。

## 作業内容

### 3.1 感情方向ベクトルの定義

```
emotion_vec[layer] = mean(resid_emotion[layer]) - mean(resid_neutral[layer])

```

### 3.2 層ごとの感情方向強度を可視化

- L1 norm
- L2 norm
- cos-sim で安定性を評価
- 層ごとの強さを line plot にする

### 3.3 モデル内での感情距離

- 感謝 vs 怒り
- 感謝 vs 謝罪
- 怒り vs 謝罪
    
    を cos-sim で算出し、2D / 3D plot で可視化
    

### 3.4 モデル間での感情方向の類似度

- GPT-2 small の gratitude_vec と
- Pythia-70M の gratitude_vec の
    
    cos-sim を計算
    
    → 感情カテゴリごとに比較表を作る
    

---

# **フェーズ4：簡易 Activation Patching（1〜2週間）**

## 目的

感情方向を操作するとモデルの出力がどう変わるか「因果的検証」を行う。

## 作業内容

### 4.1 中立文を用意

例：「今日の天気について教えてください。」

### 4.2 推論時に residual stream を改変

```
patched = resid + α * emotion_vec

```

### 4.3 比較

- baseline（操作なし）
- 感謝方向を加算
- 感謝方向を抑制
- 怒り方向を加算
- 怒り方向を抑制

### 評価

- 文末が丁寧になるか
- 感謝語が増えるか
- トーンが穏やかになるか
- 怒り方向で攻撃性が増すか（安全性に注意）

---

# **フェーズ5：結果整理と「筋の良さ」評価（1週間）**

## 目的

パイロットの成果を総括し、研究を継続すべきか判断する。

## チェック項目

- 感情方向は安定して検出されたか？
- モデル間で類似方向が確認できたか？
- 感情方向の操作で出力が変わったか？
- 小型モデルでも十分に分析可能か？
- コードは拡張可能か？（SAE、head-level 解析など）
- 「本格的な研究テーマ」として筋は良さそうか？

---

# 6. タイムライン（8週間想定）

| 週 | フェーズ |
| --- | --- |
| Week 1 | 環境構築・データ作成 |
| Week 2–3 | 内部活性抽出（モデルA/B） |
| Week 4–5 | 感情方向分析・モデル間比較 |
| Week 6–7 | Activation patching |
| Week 8 | 結果まとめ・今後の計画策定 |

---

# 7. 今後の拡張案（パイロット成功後）

- 感情カテゴリ拡張（喜び／悲しみ／恐れなど）
- 多言語（英語＋日本語→多言語へ）
- Attention head / MLP unit レベルの感情特化回路探索
- Sparse Autoencoder（SAE）で「感情特徴ユニット」の発見
- Base vs Instruct モデルでの違い解析
- LLM alignment（安全性）研究への応用

---

# 8. ToDo 全チェックリスト

- [ ]  GitHub リポジトリ作成
- [ ]  Python / TransformerLens 環境構築
- [ ]  感情プロンプトデータセット作成
- [ ]  モデルA/B の内部活性抽出スクリプト
- [ ]  感情方向ベクトル算出コード
- [ ]  モデル内・モデル間の類似度分析ノートブック
- [ ]  Activation patching 実験
- [ ]  レポート作成