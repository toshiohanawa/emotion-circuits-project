<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Circuits Project - 処理フロー図とシーケンス図</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 40px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        h3 {
            color: #555;
            margin-top: 30px;
        }
        .section {
            background-color: white;
            padding: 25px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .mermaid {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .explanation {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #17a2b8;
            margin: 15px 0;
        }
        .file-path {
            font-family: 'Courier New', monospace;
            background-color: #e9ecef;
            padding: 2px 6px;
            border-radius: 3px;
            color: #d63384;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #3498db;
            color: white;
        }
        tr:nth-child(even) {
            background-color: #f2f2f2;
        }
        .phase-box {
            border: 2px solid #3498db;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            background-color: #e8f4f8;
        }
        .phase-title {
            font-weight: bold;
            color: #2c3e50;
            font-size: 1.1em;
        }
    </style>
</head>
<body>
    <h1>Emotion Circuits Project - 処理フロー図とシーケンス図</h1>
    
    <div class="section">
        <h2>プロジェクト概要</h2>
        <p>
            このプロジェクトは、軽量〜中規模LLMを用いて、「感謝」「怒り」「謝罪」などの感情表現がモデル内部でどのように表現されているかを解析する研究プロジェクトです。
        </p>
        <p><strong>対象モデル</strong>:</p>
        <ul>
            <li><strong>小型モデル</strong>（TransformerLens）: GPT-2 small (124M, 12層), Pythia-160M (12層), GPT-Neo-125M (12層)</li>
            <li><strong>中規模モデル</strong>（LargeHFModel）: Llama3-8B (32層), Qwen3-8B (36層), Gemma3-12B (48層)</li>
        </ul>
        <p>
            <strong>核心的な研究クエスチョン</strong>:
            「異なるLLMの中に、"座標系は違うが本質的には同じ" 感情表現の部分空間は存在するのか？そしてそれを因果的に操作できるのか？」
        </p>
        <p><strong>プロファイル</strong>:</p>
        <ul>
            <li><strong>baseline</strong>: 各感情225サンプル（正式な統計検証用フルラン）</li>
            <li><strong>baseline_smoke</strong>: 各感情3-5サンプル（ハードウェア/配線確認用の最小セット）</li>
        </ul>
    </div>

    <div class="section">
        <h2>1. 全体処理フロー図</h2>
        <div class="mermaid">
            flowchart TD
                Start([プロジェクト開始]) --> Phase0[Phase 0: 環境構築]
                Phase0 --> Phase1[Phase 1: データセット構築]
                Phase1 --> Phase2[Phase 2: 活性抽出]
                Phase2 --> Phase3[Phase 3: 感情ベクトル構築]
                Phase3 --> Phase4[Phase 4: モデル間アライメント]
                Phase4 --> Phase5[Phase 5: 残差パッチング]
                Phase5 --> Phase6a[Phase 6a: Head Screening]
                Phase6a --> Phase6b[Phase 6b: Head Patching/Ablation]
                Phase6b --> Phase7[Phase 7: 統計的厳密性]
                Phase7 --> End([解析完了])

                Phase1 -->|生成物| Data[data/emotion_dataset.jsonl<br/>data/emotion_dataset_smoke.jsonl]
                Phase2 -->|生成物| Activations[results/<profile>/activations/]
                Phase3 -->|生成物| Vectors[results/<profile>/emotion_vectors/]
                Phase3 -->|生成物| Subspaces[results/<profile>/emotion_subspaces/]
                Phase4 -->|生成物| Alignment[results/<profile>/alignment/]
                Phase5 -->|生成物| Patching[results/<profile>/patching/residual/]
                Phase6a -->|生成物| HeadScores[results/<profile>/screening/head_scores_*.json]
                Phase6b -->|生成物| HeadPatching[results/<profile>/patching/head_patching/]
                Phase7 -->|生成物| Statistics[results/<profile>/statistics/]

                style Phase0 fill:#e1f5ff
                style Phase1 fill:#fff4e1
                style Phase2 fill:#e8f5e9
                style Phase3 fill:#f3e5f5
                style Phase4 fill:#fce4ec
                style Phase5 fill:#e0f2f1
                style Phase6a fill:#e8eaf6
                style Phase6b fill:#f1f8e9
                style Phase7 fill:#ffe0b2
        </div>
        
        <div class="explanation">
            <h3>フロー図の説明</h3>
            <p>
                このフロー図は、Phase 0からPhase 7までの全体的な処理の流れを示しています。
                各フェーズは前のフェーズの出力を入力として使用し、順次処理が進みます。
            </p>
            <ul>
                <li><strong>Phase 0</strong>: 環境構築とディレクトリ構造の作成</li>
                <li><strong>Phase 1</strong>: 感情プロンプトデータセットの構築（baseline/baseline_smokeプロファイル）</li>
                <li><strong>Phase 2</strong>: モデル内部活性の抽出（residual stream）</li>
                <li><strong>Phase 3</strong>: 感情方向ベクトルとPCAサブスペースの計算</li>
                <li><strong>Phase 4</strong>: モデル間サブスペースアライメント（Procrustes分析、線形写像）</li>
                <li><strong>Phase 5</strong>: Multi-token残差パッチングによる因果効果の確認</li>
                <li><strong>Phase 6a</strong>: Head Screening（感情語トークンへの反応度測定）</li>
                <li><strong>Phase 6b</strong>: Head Patching/Ablation（head出力の置換/ゼロ化）</li>
                <li><strong>Phase 7</strong>: 統計的厳密性の強化（効果量、検出力分析、k選択検証）</li>
            </ul>
            <p><strong>注意</strong>: Phase 8（中規模モデルスケーリング）は将来の拡張として計画されていますが、現在は未実装です。</p>
        </div>
    </div>

    <div class="section">
        <h2>2. データフロー図</h2>
        <div class="mermaid">
            flowchart LR
                subgraph Input["入力データ"]
                    Prompts[プロンプトJSON<br/>gratitude/anger/apology/neutral]
                end
                
                subgraph Phase1["Phase 1: データセット構築"]
                    Build[src/data/build_dataset.py]
                    Validate[src/data/validate_dataset.py]
                end
                
                subgraph Phase2["Phase 2: 活性抽出"]
                    Extract[src/analysis/run_phase2_activations.py]
                    Activations[活性データ<br/>.pkl形式<br/>results/<profile>/activations/]
                end
                
                subgraph Phase3["Phase 3: ベクトル構築"]
                    VecExtract[src/analysis/run_phase3_vectors.py]
                    Vectors[感情ベクトル<br/>.pkl形式<br/>emotion_vectors/]
                    Subspaces[サブスペース<br/>.pkl形式<br/>emotion_subspaces/]
                end
                
                subgraph Phase4["Phase 4: アライメント"]
                    Alignment[src/analysis/run_phase4_alignment.py]
                    Note4[⚠ 異なるd_model間は<br/>現在未サポート]
                end
                
                subgraph Phase5["Phase 5: 残差パッチング"]
                    ActPatch[src/analysis/run_phase5_residual_patching.py]
                    Patching[パッチング結果<br/>.pkl形式<br/>patching/residual/]
                end
                
                subgraph Phase6["Phase 6: Head解析"]
                    HeadScreen[src/analysis/run_phase6_head_screening.py<br/>Phase 6a]
                    HeadPatch[src/analysis/run_phase6_head_patching.py<br/>Phase 6b]
                end
                
                subgraph Phase7["Phase 7: 統計解析"]
                    Statistics[src/analysis/run_phase7_statistics.py]
                    Stats[統計結果<br/>.csv形式<br/>statistics/]
                end
                
                Prompts --> Build
                Build --> Validate
                Validate --> Extract
                Extract --> Activations
                Activations --> VecExtract
                VecExtract --> Vectors
                VecExtract --> Subspaces
                Subspaces --> Alignment
                Vectors --> ActPatch
                Activations --> HeadScreen
                HeadScreen --> HeadPatch
                ActPatch --> Statistics
                HeadPatch --> Statistics
                Alignment --> Statistics
                ActPatch --> Patching
                HeadPatch --> Patching
                Statistics --> Stats
                
                style Input fill:#ffe6e6
                style Phase1 fill:#fff4e1
                style Phase2 fill:#e8f5e9
                style Phase3 fill:#f3e5f5
                style Phase4 fill:#fce4ec
                style Phase5 fill:#e0f2f1
                style Phase6 fill:#e8eaf6
                style Phase7 fill:#ffe0b2
        </div>
        
        <div class="explanation">
            <h3>データフローの説明</h3>
            <p>
                この図は、データが各フェーズ間でどのように流れるかを示しています。
            </p>
            <ul>
                <li><strong>入力</strong>: 感情プロンプトJSONファイル（gratitude, anger, apology, neutral）</li>
                <li><strong>Phase 1</strong>: JSONファイルからJSONLデータセットを構築（baseline/baseline_smokeプロファイル）</li>
                <li><strong>Phase 2</strong>: JSONLデータセットからモデル内部活性（residual stream）を抽出（.pkl形式）。小型モデル（12層）と中規模モデル（32-48層）に対応</li>
                <li><strong>Phase 3</strong>: 活性データから感情方向ベクトルとPCAサブスペースを計算（デフォルト: k=8次元）</li>
                <li><strong>Phase 4</strong>: サブスペースを使用してモデル間アライメント（Procrustes分析）を実施。⚠ 異なるd_model間（小型: 768次元、中規模: 4096次元）は現在未サポート</li>
                <li><strong>Phase 5</strong>: 感情ベクトルを使用してmulti-token残差パッチングを実施。ランダム対照実験もオプションで可能</li>
                <li><strong>Phase 6a</strong>: Head Screeningで感情語トークンに反応するheadを特定（Δattention測定）</li>
                <li><strong>Phase 6b</strong>: Head Patching/Ablationで因果効果を測定（head出力の置換/ゼロ化）</li>
                <li><strong>Phase 7</strong>: Phase 5-6の結果を統計的に評価（効果量、検出力、k選択）。effect/power/kモードで実行可能</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>3. Phase 2: 活性抽出のシーケンス図</h2>
        <div class="mermaid">
            sequenceDiagram
                participant User as ユーザー
                participant Script as run_phase2_activations.py
                participant Model as HookedTransformer
                participant Hook as Hook関数
                participant File as ファイルシステム
                
                User->>Script: 実行開始 (--profile baseline --model gpt2_small)
                Script->>Model: モデルロード (gpt2_small/pythia-160m/gpt-neo-125m)
                Model-->>Script: モデル準備完了
                
                loop 各感情カテゴリ (4種類)
                    loop 各プロンプト (225サンプル/baseline)
                        Script->>Model: プロンプトをトークン化
                        Model->>Hook: Forward実行開始
                        Hook->>Hook: Residual streamをキャプチャ<br/>(resid_pre/resid_post)
                        Hook-->>Model: 活性データを返す
                        Model-->>Script: 活性データ取得
                        Script->>Script: CPUに転送・保存
                    end
                    Script->>File: 活性データを.pkl形式で保存<br/>results/<profile>/activations/<model>.pkl
                end
                
                Script->>File: MLflowログを記録
                Script-->>User: 完了
        </div>
        
        <div class="explanation">
            <h3>Phase 2の処理詳細</h3>
            <p>
                Phase 2では、各モデル（GPT-2、Pythia-160M、GPT-Neo-125M）について、
                各感情カテゴリ（gratitude, anger, apology, neutral）のプロンプトを処理し、
                モデル内部の活性（residual stream、MLP出力）を抽出します。
            </p>
            <ul>
                <li><strong>入力</strong>: JSONLデータセット（baseline: 225サンプル/感情、baseline_smoke: 3-5サンプル/感情）</li>
                <li><strong>処理</strong>: TransformerLens（小型モデル）またはLargeHFModel（中規模モデル）のHook機能を使用してresidual stream（resid_pre/resid_post）をキャプチャ</li>
                <li><strong>出力</strong>: 活性データ（.pkl形式）</li>
                <li><strong>保存先</strong>: <span class="file-path">results/<profile>/activations/<model>.pkl</span></li>
                <li><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase2_activations --profile baseline --model gpt2_small --layers 0 1 2 3 4 5 6 7 8 9 10 11 --max-samples-per-emotion 225 --device mps --batch-size 32</code></li>
                <li><strong>対応モデル</strong>: 小型モデル（gpt2_small, pythia-160m, gpt-neo-125m）、中規模モデル（llama3_8b, qwen3_8b, gemma3_12b）</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>4. Phase 3: 感情ベクトル構築のシーケンス図</h2>
        <div class="mermaid">
            sequenceDiagram
                participant User as ユーザー
                participant Script as run_phase3_vectors.py
                participant Activations as 活性データ
                participant Calculator as ベクトル計算
                participant PCA as PCA分析
                participant File as ファイルシステム
                
                User->>Script: 実行開始 (--profile baseline --model gpt2_small)
                Script->>Activations: 活性データを読み込み
                Activations-->>Script: 活性データ取得
                
                loop 各感情カテゴリ (3種類: gratitude/anger/apology)
                    Script->>Calculator: 感情語トークン位置を特定
                    Calculator-->>Script: トークン位置リスト
                    
                    loop 各層 (12層)
                        Script->>Calculator: 感情語トークンのresidual streamを平均
                        Script->>Calculator: 中立プロンプトのresidual streamを平均
                        Calculator->>Calculator: emotion_vec = mean(emotion) - mean(neutral)
                        Calculator-->>Script: 層ごとのベクトル
                    end
                    
                    Script->>Script: 層ごとのベクトルを結合
                end
                
                Script->>PCA: PCA分析でサブスペース抽出 (k=8)
                PCA-->>Script: サブスペースデータ
                Script->>Calculator: 感情間のcosine類似度を計算
                Script->>File: ベクトルを.pkl形式で保存<br/>emotion_vectors/*.pkl
                Script->>File: サブスペースを.pkl形式で保存<br/>emotion_subspaces/*.pkl
                Script-->>User: 完了
        </div>
        
        <div class="explanation">
            <h3>Phase 3の処理詳細</h3>
            <p>
                Phase 3では、Phase 2で抽出した活性データから、感情方向ベクトルとPCAサブスペースを計算します。
            </p>
            <ul>
                <li><strong>感情ベクトル</strong>: 感情語トークン（"thank", "frustrated", "sorry"など）のresidual streamを使用して、emotion_vec = mean(emotion) - mean(neutral)を計算</li>
                <li><strong>PCAサブスペース</strong>: 活性データからPCA分析でk次元サブスペースを抽出（デフォルト: k=8）</li>
            </ul>
            <p>
                <strong>出力</strong>: 
                <ul>
                    <li>感情ベクトル（.pkl形式）: <span class="file-path">results/<profile>/emotion_vectors/*.pkl</span></li>
                    <li>サブスペース（.pkl形式）: <span class="file-path">results/<profile>/emotion_subspaces/*.pkl</span></li>
                </ul>
                <strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase3_vectors --profile baseline --model gpt2_small --n-components 8 --use-torch</code>
            </p>
        </div>
    </div>

    <div class="section">
        <h2>5. Phase 4: モデル間アライメントのシーケンス図</h2>
        <div class="mermaid">
            sequenceDiagram
                participant User as ユーザー
                participant Script as run_phase4_alignment.py
                participant SubspaceA as モデルAのサブスペース
                participant SubspaceB as モデルBのサブスペース
                participant Procrustes as Procrustes分析
                participant File as ファイルシステム
                
                User->>Script: 実行開始 (--model-a gpt2_small --model-b pythia-160m)
                Script->>SubspaceA: モデルAのサブスペース読み込み
                Script->>SubspaceB: モデルBのサブスペース読み込み
                
                Script->>Procrustes: サブスペース間のoverlap計算
                Procrustes-->>Script: 初期overlap値
                
                Script->>Procrustes: Neutral空間での線形写像学習
                Procrustes->>Procrustes: Procrustes分析で最適写像を計算
                Procrustes-->>Script: 写像行列
                
                Script->>Procrustes: 写像適用後のoverlap計算
                Procrustes-->>Script: 改善後のoverlap値
                
                Script->>File: アライメント結果を.pkl形式で保存<br/>alignment/<modelA>_vs_<modelB>_*.pkl
                Script-->>User: 完了
        </div>
        
        <div class="explanation">
            <h3>Phase 4の処理詳細</h3>
            <p>
                Phase 4では、異なるモデル間で感情サブスペースの共通性を測定し、
                Neutral空間での線形写像（Procrustes分析）により座標系の違いを取り除きます。
            </p>
            <ul>
                <li><strong>入力</strong>: Phase 3で生成されたサブスペースデータ</li>
                <li><strong>処理</strong>: Procrustes分析で最適な線形写像を学習</li>
                <li><strong>出力</strong>: アライメント結果（.pkl形式）</li>
                <li><strong>保存先</strong>: <span class="file-path">results/<profile>/alignment/<modelA>_vs_<modelB>_*.pkl</span></li>
                <li><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase4_alignment --profile baseline --model-a gpt2_small --model-b pythia-160m --k-max 8 --use-torch</code></li>
            </ul>
            <p><strong>注意</strong>: 異なるd_modelを持つモデル間（小型モデルと中規模モデル）のアライメントは現在サポートされていません。</p>
        </div>
    </div>

    <div class="section">
        <h2>6. Phase 5: 残差パッチングのシーケンス図</h2>
        <div class="mermaid">
            sequenceDiagram
                participant User as ユーザー
                participant Script as run_phase5_residual_patching.py
                participant Model as HookedTransformer
                participant Vector as 感情ベクトル
                participant Hook as Patching Hook
                participant Evaluator as Evaluation
                participant File as ファイルシステム
                
                User->>Script: 実行開始 (--layers 0 3 6 9 11 --alpha 1.0)
                Script->>Model: モデルロード
                Script->>Vector: 感情ベクトル読み込み
                Script->>Evaluator: 評価器初期化<br/>(sentiment/politeness/goemotions)
                
                loop 各層 (指定層)
                    loop 各感情 (3種類)
                        loop 各プロンプト (中立プロンプト)
                            Script->>Model: Baseline生成（パッチなし）
                            Model-->>Script: Baselineテキスト（multi-token）
                            Script->>Evaluator: Baseline評価
                            Evaluator-->>Script: Baselineメトリクス
                            
                            Script->>Model: Patching生成（パッチあり）
                            Model->>Hook: Hook登録（層L、α値、パッチウィンドウ）
                            Hook->>Hook: residual += α * emotion_vector<br/>(multi-token window)
                            Hook-->>Model: パッチ適用
                            Model-->>Script: Patchedテキスト（multi-token）
                            Script->>Evaluator: Patched評価
                            Evaluator-->>Script: Patchedメトリクス
                        end
                        Script->>Script: メトリクス集計
                    end
                end
                
                opt ランダム対照実験
                    Script->>Script: ランダムベクトルでパッチング
                    Script->>Script: ランダム対照メトリクス計算
                end
                
                Script->>Script: Deltaメトリクス計算
                Script->>File: 結果を.pkl形式で保存<br/>patching/residual/*.pkl
                Script-->>User: 完了
        </div>
        
        <div class="explanation">
            <h3>Phase 4-5の処理詳細</h3>
            <p>
                Phase 4-5では、感情ベクトルをモデル内部に「パッチ」することで、
                生成テキストへの因果的影響を測定します。
            </p>
            <ul>
                <li><strong>Phase 5</strong>: Multi-token残差パッチングによる因果効果の測定</li>
                <li><strong>処理</strong>: residual streamに α * emotion_vector を加算（指定層、指定パッチウィンドウ）</li>
                <li><strong>評価</strong>: Transformerベース評価（sentiment/politeness/goemotions）</li>
                <li><strong>ランダム対照</strong>: オプションでランダムベクトルによる対照実験を実施</li>
                <li><strong>出力</strong>: パッチング結果（.pkl形式）</li>
                <li><strong>保存先</strong>: <span class="file-path">results/<profile>/patching/residual/*.pkl</span>、<span class="file-path">patching_random/*.pkl</span>（ランダム対照）</li>
                <li><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase5_residual_patching --profile baseline --model gpt2_small --layers 0 3 6 9 11 --patch-window 3 --sequence-length 30 --alpha 1.0 --max-samples-per-emotion 8 --device mps --batch-size 16 [--random-control --num-random 50]</code></li>
                <li><strong>中規模モデル例</strong>: <code>python -m src.analysis.run_phase5_residual_patching --profile baseline --model llama3_8b --layers 0 3 6 9 11 --patch-window 3 --sequence-length 30 --alpha 1.0 --max-samples-per-emotion 50 --device cuda --batch-size 8</code></li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>7. Phase 6: Head解析のシーケンス図</h2>
        <div class="mermaid">
            sequenceDiagram
                participant User as ユーザー
                participant Screen as head_screening.py
                participant Ablate as head_ablation.py
                participant Patch as head_patching.py
                participant Model as HookedTransformer
                participant Hook as Hook関数
                participant File as ファイルシステム
                
                Note over Screen: Phase 6a: Head Screening
                User->>Screen: 実行開始 (--profile baseline --model gpt2_small)
                Screen->>Model: モデルロード
                
                loop 各感情カテゴリ (3種類)
                    loop 各プロンプト (225サンプル/baseline)
                        Screen->>Model: Forward実行
                        Model->>Hook: Attention patternをキャプチャ
                        Hook->>Hook: 感情語トークンへのattentionを測定
                        Hook-->>Screen: Attention値
                    end
                    Screen->>Screen: Δattention = emotion_mean - neutral_mean
                end
                
                Screen->>File: Head scoresをJSON形式で保存<br/>screening/head_scores_<model>.json
                
                Note over Patch: Phase 6b: Head Patching/Ablation
                User->>Patch: 実行開始 (--heads "1:10")
                Patch->>Model: モデルロード
                
                loop 各プロンプト (中立プロンプト)
                    Patch->>Model: Baseline生成
                    Model-->>Patch: Baselineテキスト
                    
                    Patch->>Model: Ablation生成（Head 1:10をゼロアウト）
                    Model->>Hook: Hook登録（Head 1:10を0に）
                    Hook-->>Model: Ablation適用
                    Model-->>Patch: Ablationテキスト
                end
                
                Patch->>File: Ablation結果を.pkl形式で保存<br/>patching/head_patching/<model>_head_ablation.pkl
        </div>
        
        <div class="explanation">
            <h3>Phase 6-7の処理詳細</h3>
            <p>
                Phase 6-7では、attention headレベルでの解析を実施します。
            </p>
            <ul>
                <li><strong>Phase 6a: Head Screening</strong>: 各headが感情語トークンにどれだけ反応するかを測定（Δattention = emotion_mean - neutral_mean）。全層・全headをスクリーニング</li>
                <li><strong>Phase 6b: Head Patching/Ablation</strong>: 重要なheadをゼロアウト（ablation）して、生成への影響を測定。head出力の置換/ゼロ化により因果効果を検証</li>
                <li><strong>注意</strong>: Head Patching（pattern_v/v_onlyモード）は現在未実装です。ablationのみ実装されています。</li>
            </ul>
            <p>
                <strong>実行コマンド</strong>:
                <ul>
                    <li>Phase 6a: <code>python -m src.analysis.run_phase6_head_screening --profile baseline --model gpt2_small --layers 0 1 2 3 4 5 6 7 8 9 10 11 --max-samples-per-emotion 225 --device mps --batch-size 8</code></li>
                    <li>Phase 6b: <code>python -m src.analysis.run_phase6_head_patching --profile baseline --model gpt2_small --heads "0:0-11 3:0-11 6:0-11 9:0-11 11:0-11" --max-samples 8 --sequence-length 30 --device mps --batch-size 8</code></li>
                </ul>
                <strong>中規模モデル例</strong>（CUDA推奨）:
                <ul>
                    <li>Phase 6a: <code>python -m src.analysis.run_phase6_head_screening --profile baseline --model llama3_8b --layers 0 3 6 9 11 --max-samples-per-emotion 50 --device cuda --batch-size 8</code></li>
                    <li>Phase 6b: <code>python -m src.analysis.run_phase6_head_patching --profile baseline --model llama3_8b --heads "0:0-11 3:0-11 6:0-11 9:0-11 11:0-11" --max-samples 50 --sequence-length 30 --device cuda --batch-size 8</code></li>
                </ul>
            </p>
        </div>
    </div>

    <div class="section">
        <h2>7. 各フェーズの詳細説明</h2>
        
        <div class="phase-box">
            <div class="phase-title">Phase 1: データセット構築</div>
            <p><strong>目的</strong>: 感情プロンプトデータセットの構築</p>
            <p><strong>入力</strong>: 個別プロンプトJSONファイル（<span class="file-path">data/{emotion}_prompts.json</span>）</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/data/build_dataset.py</span>: JSONファイルからJSONLデータセットを構築（プロファイル別）</li>
                    <li><span class="file-path">src/data/validate_dataset.py</span>: データセットの整合性を確認</li>
                </ul>
            </p>
            <p><strong>出力</strong>: JSONLデータセット（<span class="file-path">data/emotion_dataset.jsonl</span>（baseline: 225サンプル/感情）、<span class="file-path">data/emotion_dataset_smoke.jsonl</span>（baseline_smoke: 3-5サンプル/感情））</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.data.build_dataset --profile baseline --input <path></code></p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 2: 活性抽出</div>
            <p><strong>目的</strong>: モデル内部活性（residual stream、MLP出力）の抽出</p>
            <p><strong>入力</strong>: JSONLデータセット</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/analysis/run_phase2_activations.py</span>: 指定モデル×指定層の活性抽出</li>
                    <li>TransformerLensのHook機能を使用してresidual stream（resid_pre/resid_post）をキャプチャ</li>
                </ul>
            </p>
            <p><strong>出力</strong>: 活性データ（<span class="file-path">results/<profile>/activations/<model>.pkl</span>）</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase2_activations --profile baseline --model gpt2_small --layers 0 1 2 3 4 5 6 7 8 9 10 11 --max-samples-per-emotion 225</code></p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 3: 感情ベクトル構築</div>
            <p><strong>目的</strong>: 感情方向ベクトルの計算</p>
            <p><strong>入力</strong>: 活性データ</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/analysis/run_phase3_vectors.py</span>: 感情語トークンベースのベクトル抽出とPCAサブスペース構築</li>
                    <li>感情間のcosine類似度を計算</li>
                    <li>PCA分析でk次元サブスペースを抽出（デフォルト: k=8）</li>
                </ul>
            </p>
            <p><strong>出力</strong>: 
                <ul>
                    <li>感情ベクトル（<span class="file-path">results/<profile>/emotion_vectors/*.pkl</span>）</li>
                    <li>サブスペース（<span class="file-path">results/<profile>/emotion_subspaces/*.pkl</span>）</li>
                </ul>
            </p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase3_vectors --profile baseline --model gpt2_small --n-components 8 --use-torch</code></p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 4: モデル間アライメント</div>
            <p><strong>目的</strong>: サブスペースの共通性を測り、線形写像で座標系の違いを取り除く</p>
            <p><strong>入力</strong>: Phase 3で生成されたサブスペースデータ</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/analysis/run_phase4_alignment.py</span>: Procrustes分析によるモデル間アライメント</li>
                    <li>Neutral空間での線形写像学習</li>
                    <li>サブスペース間のoverlap計算（before/after）</li>
                </ul>
            </p>
            <p><strong>出力</strong>: アライメント結果（<span class="file-path">results/<profile>/alignment/<modelA>_vs_<modelB>_*.pkl</span>）</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase4_alignment --profile baseline --model-a gpt2_small --model-b pythia-160m --k-max 8 --use-torch</code></p>
            <p><strong>注意</strong>: 異なるd_modelを持つモデル間（小型モデルと中規模モデル）のアライメントは現在サポートされていません。</p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 5: 残差パッチング</div>
            <p><strong>目的</strong>: Multi-token残差パッチングによる因果効果の確認</p>
            <p><strong>入力</strong>: 感情ベクトル、中立プロンプト</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/models/activation_patching.py</span>: Multi-token Activation Patching</li>
                    <li>residual streamに α * emotion_vector を加算（指定層、指定パッチウィンドウ）</li>
                    <li>Transformerベース評価（sentiment/politeness/goemotions）を使用</li>
                    <li>オプションでランダムベクトルによる対照実験</li>
                </ul>
            </p>
            <p><strong>出力</strong>: パッチング結果（<span class="file-path">results/<profile>/patching/residual/*.pkl</span>、<span class="file-path">patching_random/*.pkl</span>（ランダム対照））</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase5_residual_patching --profile baseline --model gpt2_small --layers 0 3 6 9 11 --patch-window 5 --sequence-length 30 --alpha 1.0 [--random-control --num-random 50]</code></p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 6a: Head Screening</div>
            <p><strong>目的</strong>: 感情語トークンに反応するheadの特定</p>
            <p><strong>入力</strong>: プロンプトJSONファイル</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/analysis/run_phase6_head_screening.py</span>: 各headのΔattentionを測定</li>
                    <li>感情語トークンへのattentionを測定（Δattention = emotion_mean - neutral_mean）</li>
                </ul>
            </p>
            <p><strong>出力</strong>: Head scores（<span class="file-path">results/<profile>/screening/head_scores_<model>.json</span>）</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase6_head_screening --profile baseline --model gpt2_small --layers 0 1 2 3 4 5 6 7 8 9 10 11</code></p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 6b: Head Patching/Ablation</div>
            <p><strong>目的</strong>: Head-levelでの因果的パッチング/アブレーション</p>
            <p><strong>入力</strong>: 中立プロンプト、評価器</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/analysis/run_phase6_head_patching.py</span>: Head出力のアブレーション（ゼロ化）</li>
                    <li>重要なheadをゼロアウトして、生成への影響を測定</li>
                    <li><strong>注意</strong>: Head Patching（pattern_v/v_onlyモード）は現在未実装です。ablationのみ実装されています。</li>
                </ul>
            </p>
            <p><strong>出力</strong>: Ablation結果（<span class="file-path">results/<profile>/patching/head_patching/<model>_head_ablation.pkl</span>）</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase6_head_patching --profile baseline --model gpt2_small --heads "1:10" --max-samples 225 --sequence-length 30</code></p>
        </div>

        <div class="phase-box">
            <div class="phase-title">Phase 7: 統計的厳密性の強化</div>
            <p><strong>目的</strong>: 効果量・検出力分析・k選択の統計的検証</p>
            <p><strong>入力</strong>: Phase 5-6の実験結果（Patching、Head解析）、Phase 4のアライメント結果（k選択用）</p>
            <p><strong>処理</strong>:
                <ul>
                    <li><span class="file-path">src/analysis/run_phase7_statistics.py</span>: 統計CLIパイプライン</li>
                    <li><span class="file-path">src/analysis/statistics/effect_sizes.py</span>: Cohen's d、t検定、ブートストラップ信頼区間</li>
                    <li><span class="file-path">src/analysis/statistics/power_analysis.py</span>: 事後検出力と必要サンプルサイズの推定</li>
                    <li><span class="file-path">src/analysis/statistics/k_selection.py</span>: k値の最適性をブートストラップで検証</li>
                </ul>
            </p>
            <p><strong>出力</strong>: 統計結果（<span class="file-path">results/<profile>/statistics/effect_sizes.csv</span>、<span class="file-path">power_analysis.csv</span>、<span class="file-path">k_selection.csv</span>）</p>
            <p><strong>実行コマンド</strong>: <code>python -m src.analysis.run_phase7_statistics --profile baseline --mode all --n-jobs 4</code>（<code>--mode effect|power|k</code>で個別実行も可能。kモードはPhase4が必要なため現在実行不可）</p>
        </div>
    </div>

    <div class="section">
        <h2>8. 主要なモジュールとその役割</h2>
        <table>
            <thead>
                <tr>
                    <th>モジュール</th>
                    <th>役割</th>
                    <th>フェーズ</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><span class="file-path">src/data/build_dataset.py</span></td>
                    <td>プロンプトJSONからJSONLデータセットを構築</td>
                    <td>Phase 1</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase2_activations.py</span></td>
                    <td>モデル内部活性の抽出（CLI）</td>
                    <td>Phase 2</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/models/activation_api.py</span></td>
                    <td>活性抽出API（HookedTransformer/LargeHFModel統一）</td>
                    <td>Phase 2</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase3_vectors.py</span></td>
                    <td>感情ベクトル/サブスペース構築（CLI）</td>
                    <td>Phase 3</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase4_alignment.py</span></td>
                    <td>モデル間アライメント（CLI）</td>
                    <td>Phase 4</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase5_residual_patching.py</span></td>
                    <td>Multi-token残差パッチング（CLI）</td>
                    <td>Phase 5</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase6_head_screening.py</span></td>
                    <td>Headスクリーニング（CLI）</td>
                    <td>Phase 6a</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase6_head_patching.py</span></td>
                    <td>Head patching/ablation（CLI）</td>
                    <td>Phase 6b</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/run_phase7_statistics.py</span></td>
                    <td>統計解析（effect/power/k）</td>
                    <td>Phase 7</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/models/model_registry.py</span></td>
                    <td>モデルレジストリ（小型/中規模モデル定義）</td>
                    <td>全Phase</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/config/project_profiles.py</span></td>
                    <td>プロファイル設定（baseline/baseline_smoke）</td>
                    <td>全Phase</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/analysis/evaluation.py</span></td>
                    <td>Transformerベース評価（Sentiment、Politeness、GoEmotions）</td>
                    <td>Phase 5-7</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/data/build_dataset.py</span></td>
                    <td>プロファイル別データセット構築</td>
                    <td>Phase 1</td>
                </tr>
                <tr>
                    <td><span class="file-path">src/data/validate_dataset.py</span></td>
                    <td>データセット整合性確認</td>
                    <td>Phase 1</td>
                </tr>
            </tbody>
        </table>
    </div>

    <div class="section">
        <h2>9. データの流れと依存関係</h2>
        <div class="mermaid">
            graph TD
                A[プロンプトJSON<br/>gratitude/anger/apology/neutral] --> B[Phase 1: データセット構築]
                B --> C[JSONLデータセット<br/>280サンプル]
                C --> D[Phase 2: 活性抽出]
                D --> E[活性データ<br/>.pkl形式<br/>30-40MB/ファイル]
                E --> F[Phase 3: ベクトル構築]
                E --> G[Phase 3.5: サブスペース解析]
                F --> H[感情ベクトル<br/>.pkl形式<br/>109KB/ファイル]
                G --> I[サブスペースデータ<br/>.pkl形式<br/>1.4MB/ファイル]
                G --> J[アライメント結果<br/>.pkl形式]
                H --> K[Phase 4: Activation Patching]
                H --> L[Phase 5: Layer/α Sweep]
                E --> M[Phase 6: Head Screening]
                M --> N[Head Scores<br/>JSON形式<br/>115KB]
                E --> O[Phase 6: Head Ablation]
                N --> P[Phase 7: Head Patching]
                O --> P
                K --> Q[Patching結果<br/>.pkl形式]
                L --> R[Sweep結果<br/>.pkl形式<br/>1.4MB]
                P --> S[Head Patching結果<br/>.pkl形式]
                
                style A fill:#ffe6e6
                style C fill:#fff4e1
                style E fill:#e8f5e9
                style H fill:#f3e5f5
                style I fill:#fce4ec
                style N fill:#e8eaf6
                style Q fill:#e0f2f1
                style R fill:#fff9c4
                style S fill:#f1f8e9
        </div>
        
        <div class="explanation">
            <h3>データ依存関係の説明</h3>
            <p>
                この図は、各フェーズ間でのデータの依存関係を示しています。
                矢印は「入力→出力」の関係を表します。
            </p>
            <ul>
                <li><strong>Phase 1</strong>: プロンプトJSON → JSONLデータセット</li>
                <li><strong>Phase 2</strong>: JSONLデータセット → 活性データ（Phase 3とPhase 3.5の両方で使用）</li>
                <li><strong>Phase 3</strong>: 活性データ → 感情ベクトル（Phase 4-5で使用）</li>
                <li><strong>Phase 3.5</strong>: 活性データ → サブスペースデータ・アライメント結果</li>
                <li><strong>Phase 4-5</strong>: 感情ベクトル → Patching結果</li>
                <li><strong>Phase 6</strong>: 活性データ → Head Scores → Head Ablation結果</li>
                <li><strong>Phase 7</strong>: Head Scores + 活性データ → Head Patching結果</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>10. 評価フロー図</h2>
        <div class="mermaid">
            flowchart TD
                A[生成テキスト] --> B[SentimentEvaluator]
                B --> C[CardiffNLP Sentiment<br/>POSITIVE/NEGATIVE/NEUTRAL]
                B --> D[Stanford Politeness<br/>politeness_score]
                B --> E[GoEmotions<br/>joy/anger/sadness/etc.]
                
                C --> F[メトリクス集計]
                D --> F
                E --> F
                
                F --> G[Baselineメトリクス]
                F --> H[Patchedメトリクス]
                
                G --> I[Deltaメトリクス計算]
                H --> I
                
                I --> J[MLflowログ記録]
                I --> K[可視化<br/>ヒートマップ/バイオリン]
                
                style A fill:#ffe6e6
                style B fill:#e8f5e9
                style C fill:#fff4e1
                style D fill:#f3e5f5
                style E fill:#fce4ec
                style I fill:#e0f2f1
                style J fill:#fff9c4
                style K fill:#e8eaf6
        </div>
        
        <div class="explanation">
            <h3>評価フローの説明</h3>
            <p>
                この図は、生成テキストの評価プロセスを示しています。
                ヒューリスティック指標ではなく、Transformerベースの評価器を使用します。
            </p>
            <ul>
                <li><strong>CardiffNLP Sentiment</strong>: 感情分析（POSITIVE/NEGATIVE/NEUTRAL）</li>
                <li><strong>Stanford Politeness</strong>: 丁寧さスコア</li>
                <li><strong>GoEmotions</strong>: 27種類の感情分類（joy, anger, sadnessなど）</li>
            </ul>
            <p>
                BaselineとPatchedのメトリクスを比較し、Deltaメトリクスを計算します。
                結果はMLflowに記録され、可視化されます。
            </p>
        </div>
    </div>

    <div class="section">
        <h2>11. 実行コマンドの例</h2>
        <table>
            <thead>
                <tr>
                    <th>フェーズ</th>
                    <th>実行コマンド</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Phase 1</td>
                    <td><code>python -m src.data.build_dataset --profile baseline --input <path></code></td>
                </tr>
                <tr>
                    <td>Phase 2</td>
                    <td><code>python -m src.analysis.run_phase2_activations --profile baseline --model gpt2_small --layers 0 1 2 3 4 5 6 7 8 9 10 11 --max-samples-per-emotion 225 --device mps --batch-size 32</code></td>
                </tr>
                <tr>
                    <td>Phase 3</td>
                    <td><code>python -m src.analysis.run_phase3_vectors --profile baseline --model gpt2_small --n-components 8 --use-torch --device mps</code></td>
                </tr>
                <tr>
                    <td>Phase 4</td>
                    <td><code>python -m src.analysis.run_phase4_alignment --profile baseline --model-a gpt2_small --model-b pythia-160m --k-max 8 --use-torch --device mps</code><br/><small>⚠ 異なるd_model間は未サポート</small></td>
                </tr>
                <tr>
                    <td>Phase 5</td>
                    <td><code>python -m src.analysis.run_phase5_residual_patching --profile baseline --model gpt2_small --layers 0 3 6 9 11 --patch-window 3 --sequence-length 30 --alpha 1.0 --max-samples-per-emotion 8 --device mps --batch-size 16</code></td>
                </tr>
                <tr>
                    <td>Phase 6a</td>
                    <td><code>python -m src.analysis.run_phase6_head_screening --profile baseline --model gpt2_small --layers 0 1 2 3 4 5 6 7 8 9 10 11 --max-samples-per-emotion 225 --device mps --batch-size 8</code></td>
                </tr>
                <tr>
                    <td>Phase 6b</td>
                    <td><code>python -m src.analysis.run_phase6_head_patching --profile baseline --model gpt2_small --heads "0:0-11 3:0-11 6:0-11 9:0-11 11:0-11" --max-samples 8 --sequence-length 30 --device mps --batch-size 8</code></td>
                </tr>
                <tr>
                    <td>Phase 7</td>
                    <td><code>python -m src.analysis.run_phase7_statistics --profile baseline --mode all --n-jobs 4</code><br/><small>（--mode effect|power|k で個別実行も可能）</small></td>
                </tr>
            </tbody>
        </table>
    </div>

    <div class="section">
        <h2>12. 重要な発見のまとめ</h2>
        <ul>
            <li><strong>Token-basedベクトルの有効性</strong>: 感情語トークンベースのベクトルがより明確な感情表現を抽出</li>
            <li><strong>サブスペースレベルでの共通性</strong>: モデル間overlap 0.13-0.15（ランダムより高い）</li>
            <li><strong>線形写像による大幅改善</strong>: Neutral空間での線形写像により、overlapが0.001から0.99に改善（同d_model間のみ）</li>
            <li><strong>Multi-token生成の重要性</strong>: 単一トークンでは検出できないスタイル変化がmulti-token生成で検出可能</li>
            <li><strong>Transformerベース評価の有効性</strong>: ヒューリスティック指標では検出できなかった効果がTransformerベース評価（sentiment/politeness/goemotions）で検出可能</li>
            <li><strong>統計的厳密性の確認（Phase 7）</strong>: 効果量、検出力分析、k選択検証により統計的検証を実施</li>
            <li><strong>中規模モデルへのスケーリング</strong>: 小型モデル（12層）と中規模モデル（32-48層）の両方に対応。層分割実行により大規模モデルも処理可能</li>
            <li><strong>プロファイルシステム</strong>: baseline（225サンプル/感情）とbaseline_smoke（3-5サンプル/感情）で柔軟な実験設計が可能</li>
        </ul>
    </div>

    <div class="section">
        <h2>13. 参考文献とリンク</h2>
        <ul>
            <li><strong>TransformerLens</strong>: <a href="https://github.com/neelnanda-io/TransformerLens">https://github.com/neelnanda-io/TransformerLens</a></li>
            <li><strong>HuggingFace Transformers</strong>: <a href="https://huggingface.co/docs/transformers">https://huggingface.co/docs/transformers</a></li>
            <li><strong>実装計画</strong>: <span class="file-path">docs/implementation_plan.md</span></li>
            <li><strong>Phaseレポート</strong>: <span class="file-path">docs/report/phase*.md</span></li>
        </ul>
    </div>

    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</body>
</html>
