## Emotion Circuits Master Plan

### 1. ビジョンと出発点

機械は感情をどう扱っているのか？この疑問は、LLMの応答からにじみ出るトーンや雰囲気、微妙な礼儀や共感性に気づいたときに芽生えた。ある大学教員の「LLMの入出力しか見えないのは人と同じだよね」という言葉は、この問いをさらに深めるきっかけとなった。

しかし、人間は感情を「感じて」から「表現する」までに、内的な状態の変化と、その影響による応答の変化がある。もしLLMにも似たような流れがあるなら、感情はどこで取り込まれ、どこを通り、どこで出力に関与するのだろう？

この研究は、Transformerモデル内部での"感情の流れ"を、ベクトルとして、回路として、構造として探る試みである。

---

### 2. 核心となる問い

このプロジェクトを貫く問いは、次の三つに整理できる。

* **Q1: 単一モデル内部での「感情の流れ」はどのようになっているのか？**

  感情的な入力（感謝・怒り・謝罪など）は、どの層・どのヘッド・どの残差方向に書き込まれ、どのように伝搬し、どこで読み出されて最終的な出力トーンに影響を与えるのか。
* **Q2: 異なるLLMの中に、「座標系は違うが本質的には同じ」感情表現サブスペースは存在するのか？**

  GPT-2 / Pythia / GPT-Neo といった異なるモデル間で、感情表現の部分空間はどれほど似ているのか。それらは線形写像（座標変換）によってどこまで重ね合わせることができるのか。
* **Q3: その共通の感情サブスペースや回路を、因果的に操作することはできるのか？**

  残差方向へのパッチングや注意ヘッドのpatch/ablationによって、モデルの出力感情（sentiment, politeness, emotions）が意図的に変化するのか。ランダム方向との比較で、その効果が本当に特異的であると確認できるか。

Q1は「モデルの中を流れる感情のダイナミクス」を理解する問い、Q2は「モデル間で共有される感情の幾何学」を捉える問い、Q3は「それらを使ってモデルを制御できるか」という問いと言い換えられる。以降のフェーズ設計は、この三つの問いに少しずつ答えを積み上げていくためのものになっている。

---

### 3. 技術的アプローチ

この研究は、「感情の流れ」を解き明かすために、**概念レベルの4ステップ構造**と、**技術的な3つの柱**の両方に基づいて進める。

#### 3.1 概念フレームワーク：書き込み → 伝搬 → 読み出し → 出力影響

1. **書き込み（write-in）**

   感情語トークンや文脈に対して、どの層・どのattention head・どのMLPが感情情報を書き込むのかを調べる。

   * 感情語への注意分布（Δattention）
   * 残差ストリームの感情方向への投影
2. **伝搬（propagation）**

   書き込まれた感情成分が、residual stream を通じてどの層まで運ばれるか、途中で減衰・変質しないかを追跡する。

   * 層ごとの感情ベクトルのノルム
   * サブスペース重なりや方向の安定性
3. **読み出し（read-out）**

   どの層・どのhead・どのMLPが、その感情成分を最終予測（次トークン分布）やスタイルに反映しているのかを特定する。

   * 重要headのスクリーニング（Δattention, Δlogits）
   * OV/QK分解やpatchingによる因果検証
4. **出力影響（behavioral effect）**

   介入の有無で、生成文のsentiment / politeness / emotionsがどのように変化するかを定量的に評価する。

   * 外部モデルによる自動評価（RoBERTa系）
   * 将来的には人間評価も含む

この4ステップを、小型モデル → 中規模モデルへと拡張しながら繰り返すことで、感情回路のスケーリング像を描いていく。

#### 3.2 技術的な3本柱（T1〜T3）

研究を支える実装レベルの基盤として、次の三つを「技術の柱」として明示的に採用する。

* **T1: Multi-token Activation Patching**

  単一トークンではなく、10〜30トークン程度の生成過程全体に対して残差パッチングを行う。これにより、単語レベルでは見えづらい「スタイル」や「トーン」の変化を捉える。
* **T2: Transformer-based Evaluation**

  感情や礼儀正しさの評価を、人手の主観や単純なキーワードカウントではなく、既存の強力なTransformerモデル（sentiment / politeness / GoEmotionsなど）に委ねる。これにより、

  * 再現性
  * 他研究との比較可能性
  * 論文化しやすさ

    が大きく向上する。
* **T3: Random Baseline & Statistical Testing**

  感情ベクトルと同じノルムを持つランダム方向で同様のパッチングを行い、

  * 効果量（Cohen's d）
  * パーミュテーション検定
  * ブートストラップによる信頼区間

    などを用いて、「感情ベクトルの効果がランダムでは説明できないこと」を統計的に確認する。

T1〜T3は、Phase 5以降の設計でとくに重要になる。今後のフェーズでは、どの段階でどの柱を強化・拡張するのかを意識しながら進める。

#### 3.3 研究スタイル（メタ原則）

このプロジェクトには、技術的な手法に加えて、次のような「進め方の原則」がある：

* **失敗を起点に問いを深める**

  Phase 3で「モデル間類似度ほぼ0」という一見失敗にも見える結果が出たとき、

  * データの取り方を見直す（sentence-end → token-based）
  * 見方を変える（単一ベクトル → サブスペース）
  * 変換を導入する（alignment）

    というように、仮説を棄却するのではなく、より深い問いへの入口として扱ってきた。この姿勢を今後も維持する。
* **スケールよりも「小さい世界の完全理解」を優先する**

  まずは 3モデル×4感情という限られた設定を徹底的に理解し、その後で中規模モデルや多言語へと慎重に拡張する。これにより、「何がスケール不変で、何がスケール依存か」を明瞭に切り分けられる。
* **観察 → 因果 → 構造 → アライメント → 回路 の順に進める**

  いきなり回路図を描こうとせず、まず観察してから因果的介入を試し、その後で構造化（サブスペース・回路）とアライメントに進むという順序を大切にする。

このメタ原則は、今後迷ったときに「どこから立て直すか」を教えてくれるコンパスとなる。

---

### 4. フェーズ別ロードマップ

ここでは、この研究を **航海日誌と未来の航路図** の両方として整理する。

すでに完了したフェーズは「どこまで来たか」を、これからのフェーズは「どこへ向かうか」を示す。

---

#### ✅ Phase 0：観測装置の構築（環境と道具をそろえる）

 **目的** : LLMの内部状態（活性）を安全かつ再現性高く観測できる「望遠鏡」をつくる。

 **やったこと** :

* Hugging Face Transformers と独自ラッパを用いて、GPT-2 / Pythia / GPT-Neo の
  * 残差ストリーム
  * MLP出力
  * attention重み（必要に応じて）

    をフックできるインフラを整備
* 実験プロファイル（baseline / extended）や結果保存パスを一元管理する `ProjectContext` を設計
* MLflow やファイル構造を整え、「同じ実験を何度でも再現できる」状態にした

 **このフェーズの意味** : ここで、単なるプロンプト遊びから一歩進み、「LLMの中身を計測する研究者の視点」を手に入れた。

---

#### ✅ Phase 1：感情データセット構築（感情の“試験紙”をつくる）

 **目的** : 感情回路を刺激するための、ノイズの少ない・バランスの取れた感情文セットをつくる。

 **やったこと** :

* 感謝 / 怒り / 謝罪 / 中立 の4感情について、短くはっきりした英語文を合計680文作成
  * Baseline: 各70文
  * Extended: 各100文
* GPT-2トークナイザでトークン長を確認し、平均約7トークンという「扱いやすい長さ」に調整
* 感情語（thank, sorry, angry など）が明示的に含まれるよう配慮し、後続の token-based 解析の土台をつくった

 **このフェーズの意味** : 感情回路を観測するための「テストベンチ」を手作りした。ここから先の全フェーズは、この試験紙にモデルを浸して色の変化を観察する営みと言える。

---

#### ✅ Phase 2：活性抽出（感情刺激に対する“脳波”を記録する）

 **目的** : 感情文を入力したとき、各層・各トークンでどのような活性が生じるかを網羅的に記録する。

 **やったこと** :

* GPT-2 / Pythia-160M / GPT-Neo-125M それぞれについて、全12層の
  * 残差ストリーム
  * MLP出力

    を全サンプル・全トークンに対して保存
* 形状 `[n_layers][n_samples][seq_len, d_model]` のテンソルとして整備し、約431MBの「感情脳波ログ」を作成
* 実行時ログやMLflowと紐づけ、どのrunがどの活性ファイルに対応するかを追跡可能にした

 **このフェーズの意味** : 以降のすべての解析（ベクトル構築、サブスペース、パッチング、head解析）の“生データ”がここで揃った。

---

#### ✅ Phase 3：感情ベクトル構築（感情の“方向”を見つける）

 **目的** : 「この方向に進むと感謝が強くなる」「この方向に進むと怒りが強くなる」といった、感情の線形方向を同定する。

 **やったこと** :

* 2種類の感情ベクトルを構築
  * sentence-end ベクトル：文章末トークンの残差を平均
  * token-based ベクトル：感情語トークン位置の残差を平均
* Gratitude vs Anger のcos類似度を比較
  * sentence-end: 約0.37
  * token-based: 約0.16（より明確に分離）
* 層ごとのL1/L2ノルムを解析し、Layer 9〜11で感情成分が最も強くなることを確認

 **このフェーズの意味** : 「感情は残差空間のどこかに存在する」はず、という仮説に対して、「確かにこの方向がそれらしい」という証拠を得たフェーズ。ここで初めて“感情ベクトル”という操作可能なオブジェクトを手にした。

---

#### ✅ Phase 3.5：サブスペース解析とアライメント（モデル間で“感情の地形”を比べる）

 **目的** : モデルごとに感情サブスペースを求め、それらがどの程度似ているか／線形写像でどこまで揃うかを調べる。

 **やったこと** :

* 各モデルで感情ベクトル集合にPCAを適用し、k=10の感情サブスペースを抽出
* GPT-2 ↔ Pythia-160M ↔ GPT-Neo-125M のサブスペースoverlapを計算
  * いずれの組み合わせも ≈0.14〜0.15 で、ランダム基準より明確に高い
* Neutral alignment（中立文に基づく線形写像）を学習し、
  * 整列前のcos² ≈ 0.001
  * 整列後のcos² ≈ 0.99 を達成
* Procrustes alignmentでも改善を確認しつつ、線形写像が主な構造を捉えていることを確認

 **このフェーズの意味** : 「モデルごとにバラバラの世界を見ているのではなく、 **座標系が違うだけで見ている“感情地形”はほぼ同じ** 」という強い示唆を得た。小型モデル間でここまできれいにalignできることは、今後のスケーリング研究の足場になる。

---

#### ✅ Phase 4：残差パッチング（感情方向を“注入”してみる）

 **目的** : 見つけた感情方向が、本当に生成テキストの感情トーンを操作できるかを確かめる。

 **やったこと** :

* 中立プロンプトに対して、特定層の残差に

  `residual += α * emotion_vector`

  を適用し、その後の生成文を観察
* α=1.0 付近で明確なスタイル変化（感謝のにじみ、怒りの増加など）を確認
* 一方でαを大きくしすぎると、反復表現や不自然な文が増えることも観測
* 1トークン生成では変化がわかりづらく、10〜30トークン生成することで効果がよりクリアになると判明

 **このフェーズの意味** : 感情ベクトルが単なる解析用のエンベディングではなく、**モデルの振る舞いを変える“操作レバー”である**ことを実験的に確認した重要なステップ。T1（multi-token patching）の重要性がここで明らかになった。

---

#### ✅ Phase 5：層×αスイープ実験（どの層がどれだけ“効く”のか測る）

 **目的** : どの層でどれくらい感情方向を加えると、最も自然かつ効果的に感情が表出するかを定量的に測る。

 **やったこと** :

* 対象層：Layer 3, 5, 7, 9, 11
* α ∈ {−2, −1, −0.5, 0, 0.5, 1, 2}
* 生成文を
  * sentimentモデル
  * politenessモデル
  * GoEmotionsなどのemotionモデル

    で自動評価（T2）
* Layer 9, 11 付近で最も強い効果が得られ、α=0.5〜1.0が「効きすぎず自然さも保つ」レンジであることがわかった
* α=2.0 では崩壊しやすく、感情方向の線形介入には上限があることも確認

 **このフェーズの意味** : 感情回路が「どこで最大化されるか」「どの程度までなら安全にいじれるか」という**チューニングカーブ**が見えてきた。これは将来の制御LLM設計に直結する知見であり、T1×T2の組み合わせが有効に機能した例でもある。

---

#### ✅ Phase 6：HeadスクリーニングとAblation（どのヘッドが“感情に反応しているか”を探す）

 **目的** : 感情語トークンに対して、どのattention headがどれだけ追加の注意を向けているかを測り、候補headを特定する。

 **やったこと** :

* 感情文 vs 中立文で、各headの感情語トークンへのattention差分 Δattention を計算
* Gratitude では Layer 1 Head 10 がΔ≈0.34でトップ、他にも Layer 3 Head 2, Layer 1 Head 11 などが高スコア
* Ablation実験として、Layer 1 Head 10 を無効化し、生成文のsentimentやgratitudeキーワードを比較
  * わずかな変化のみ（分散回路である可能性を示唆）

 **このフェーズの意味** : ここで初めて、「このheadたちが感情処理の**入口**かもしれない」という具体的な当たりがついた。まだ関連性は相関レベルだが、次の因果パッチングへの重要な布石となった。

---

#### ✅ Phase 7：Headパッチング（特定ヘッドが本当に“因果的に効くか”を試す）

 **目的** : Phase 6で見つけた重要headに対して、出力をパッチングし、感情表現に因果的な影響を与えるかどうかを検証する。

 **やったこと** :

* Layer 1 Head 10 を対象に、pattern_v / v_only などのモードでhead出力を差し替え
* 中立プロンプトに対してpatch有無で多数サンプルを生成し、
  * sentimentスコア
  * gratitude関連キーワード出現数

    などを比較（T2）
* 一例として、pattern_vモードで
  * sentiment: 0.5832 → 0.5981（+0.0149）
  * gratitudeキーワード: 4 → 8（2倍）

    という変化を確認
* 今後は、ランダムheadやランダム方向との比較を導入し、T3の枠組みを強化していく予定

 **このフェーズの意味** : 「このheadは感情語に反応している」だけでなく、「 **このheadをいじると感情的な出力が増える** 」という因果的なリンクを示すことに成功した。感情回路研究が“観察の段階”から“介入と制御の段階”へ進んだ瞬間である。

---

#### 🧪 Phase 7.5（これから）：統計的厳密性の強化（Significance & Effect Size Validation）

 **目的** : Phase 5〜7で得られた効果（残差パッチング・headパッチング・サブスペース構造）について、p値・信頼区間・効果量などの統計的指標を明示し、「small but consistent」なシグナルであることを誠実に示す。

---

#### 🔭 Phase 8（これから）：中規模モデルへのスケーリング（感情回路の“成長”を見る）

 **目的** : 160Mクラスで見つけた構造が、410M〜1.3B〜8Bといった中規模モデルでどう変化・安定化するかを調べる。

 **やること（案）** :

* Pythia 410M, GPT-J, 1.3Bクラスなどを対象に、Phase 1〜7 と同様のpipelineを適用
* 感情ベクトルの分離度、サブスペースoverlap、alignmentのしやすさを比較（Q2）
* 重要headの層位置や数がスケールとともにどう変わるかをトレース（Q1/Q2）
* T1〜T3の枠組みをそのままスケールさせ、スケール依存・不変な性質を切り分ける

 **このフェーズがくれるもの** : 「小さな脳で見つかった感情回路が、大きな脳ではどう進化するか」という“成長の物語”。卒論・修論レベルのしっかりしたストーリーになる。

---

#### 🌌 Phase 9（これから）：感情回路の構造的解剖（OV/QKとmulti-head回路）

 **目的** : 単一headではなく、複数head＋MLPを含む回路として感情処理を再構成する。

 **やること（案）** :

* 重要headのOV/QK行列を解析し、「どのトークンから何を読み取り、どのトークンに何を書いているか」を特定
* "感情を拾うhead"、"感情を集約するhead"、"感情を出力に反映するhead" の役割分担を推定
* 複数headを同時にpatch/ablateし、単一headのときとは異なる大きな効果を測定（Q3）
* 必要に応じてT1〜T3を回路単位に拡張し、回路全体の因果効果を評価

 **このフェーズがくれるもの** : 「感情回路」が単なる感情ベクトルや1つのheadではなく、**小さなモジュールネットワーク**として存在することを描き出せるようになる。

---

#### 🌍 Phase 10（これから）：多言語・多属性への一般化

 **目的** : 感情回路の構造が英語以外や、感情以外の属性でもどこまで共通するかを探る。

 **やること（案）** :

* 日本語・他言語データセットで同様の感情ベクトル・パッチング実験を行う
* politeness, formality, humor, threat など他の軸に対してもサブスペースと回路を探索
* 言語間・属性間で共通する回路パターン／異なるパターンを整理（Q2/Q3）
* 評価にはT2を活用し、人間評価も組み合わせてT3の枠組みを強化

 **このフェーズがくれるもの** : 「LLMの中にある“社会性”の回路」の片鱗が見えてくる。人が持つ多様なスタイルや感情が、どれくらい共通構造で支えられているかを知る手がかりになる。

---

#### 🚢 Phase 11（これから）：応用と評価（感情回路を“使ってみる”）

 **目的** : 見つけた回路とベクトルを、実際の生成制御や安全性・表現デザインに生かしてみる。

 **やること（案）** :

* 感情回路を使ったトーン調整エージェント（感謝多め／攻撃性低めなど）のプロトタイプを作る
* 人間評価で、パッチング前後の応答の自然さ・伝達される感情を比較（T2/T3）
* alignmentやRLHFと組み合わせ、機械論的制御＋データ駆動制御のハイブリッドの可能性を探る

 **このフェーズがくれるもの** : 研究が「ただの解析」で終わらず、**現実のLLMデザインや運用の指針**に還元される。ここまで来ると、“LLMの中にどんな感情回路を持たせたいか”という設計の議論もできるようになる。

---

#### 📄 論文パッケージとしての区切り

今後の学術アウトプットを考えると、フェーズ群はおおよそ次のような「論文パッケージ」としてまとめられる：

| パッケージ | 対応フェーズ | 主題                                                                   |
| ---------- | ------------ | ---------------------------------------------------------------------- |
| Paper 1    | Phase 1〜7   | 小型モデルにおける感情サブスペース、残差パッチング、headレベル因果回路 |
| Paper 2    | Phase 8〜9   | モデル規模のスケーリングによる感情回路の変化と安定性                   |
| Paper 3    | Phase 10〜11 | 多言語・多属性への一般化と、感情回路を用いた制御・応用                 |

この区切りを意識しておくことで、「今どのパッケージのどの部分を進めているのか」「卒論・修論としてどこまでをまとめるか」が見通しやすくなる。

---

ここまでが、感情回路研究の「過去の航海ログ」と「これからの航路図」である。迷ったときは、今どのフェーズにいて、次にどの灯台を目指したいのかを、この一覧に照らして確かめればよい。

### 5. 出口と応用

ここでは、この研究を **航海日誌と未来の航路図** の両方として整理する。

すでに完了したフェーズは「どこまで来たか」を、これからのフェーズは「どこへ向かうか」を示す。

---

#### ✅ Phase 0：観測装置の構築（環境と道具をそろえる）

 **目的** : LLMの内部状態（活性）を安全かつ再現性高く観測できる「望遠鏡」をつくる。

 **やったこと** :

* Hugging Face Transformers と独自ラッパを用いて、GPT-2 / Pythia / GPT-Neo の
  * 残差ストリーム
  * MLP出力
  * attention重み（必要に応じて）

    をフックできるインフラを整備
* 実験プロファイル（baseline / extended）や結果保存パスを一元管理する `ProjectContext` を設計
* MLflow やファイル構造を整え、「同じ実験を何度でも再現できる」状態にした

 **このフェーズの意味** : ここで、単なるプロンプト遊びから一歩進み、「LLMの中身を計測する研究者の視点」を手に入れた。

---

#### ✅ Phase 1：感情データセット構築（感情の“試験紙”をつくる）

 **目的** : 感情回路を刺激するための、ノイズの少ない・バランスの取れた感情文セットをつくる。

 **やったこと** :

* 感謝 / 怒り / 謝罪 / 中立 の4感情について、短くはっきりした英語文を合計680文作成
  * Baseline: 各70文
  * Extended: 各100文
* GPT-2トークナイザでトークン長を確認し、平均約7トークンという「扱いやすい長さ」に調整
* 感情語（thank, sorry, angry など）が明示的に含まれるよう配慮し、後続の token-based 解析の土台をつくった

 **このフェーズの意味** : 感情回路を観測するための「テストベンチ」を手作りした。ここから先の全フェーズは、この試験紙にモデルを浸して色の変化を観察する営みと言える。

---

#### ✅ Phase 2：活性抽出（感情刺激に対する“脳波”を記録する）

 **目的** : 感情文を入力したとき、各層・各トークンでどのような活性が生じるかを網羅的に記録する。

 **やったこと** :

* GPT-2 / Pythia-160M / GPT-Neo-125M それぞれについて、全12層の
  * 残差ストリーム
  * MLP出力

    を全サンプル・全トークンに対して保存
* 形状 `[n_layers][n_samples][seq_len, d_model]` のテンソルとして整備し、約431MBの「感情脳波ログ」を作成
* 実行時ログやMLflowと紐づけ、どのrunがどの活性ファイルに対応するかを追跡可能にした

 **このフェーズの意味** : 以降のすべての解析（ベクトル構築、サブスペース、パッチング、head解析）の“生データ”がここで揃った。

---

#### ✅ Phase 3：感情ベクトル構築（感情の“方向”を見つける）

 **目的** : 「この方向に進むと感謝が強くなる」「この方向に進むと怒りが強くなる」といった、感情の線形方向を同定する。

 **やったこと** :

* 2種類の感情ベクトルを構築
  * sentence-end ベクトル：文章末トークンの残差を平均
  * token-based ベクトル：感情語トークン位置の残差を平均
* Gratitude vs Anger のcos類似度を比較
  * sentence-end: 約0.37
  * token-based: 約0.16（より明確に分離）
* 層ごとのL1/L2ノルムを解析し、Layer 9〜11で感情成分が最も強くなることを確認

 **このフェーズの意味** : 「感情は残差空間のどこかに存在する」はず、という仮説に対して、「確かにこの方向がそれらしい」という証拠を得たフェーズ。ここで初めて“感情ベクトル”という操作可能なオブジェクトを手にした。

---

#### ✅ Phase 3.5：サブスペース解析とアライメント（モデル間で“感情の地形”を比べる）

 **目的** : モデルごとに感情サブスペースを求め、それらがどの程度似ているか／線形写像でどこまで揃うかを調べる。

 **やったこと** :

* 各モデルで感情ベクトル集合にPCAを適用し、k=10の感情サブスペースを抽出
* GPT-2 ↔ Pythia-160M ↔ GPT-Neo-125M のサブスペースoverlapを計算
  * いずれの組み合わせも ≈0.14〜0.15 で、ランダム基準より明確に高い
* Neutral alignment（中立文に基づく線形写像）を学習し、
  * 整列前のcos² ≈ 0.001
  * 整列後のcos² ≈ 0.99 を達成
* Procrustes alignmentでも改善を確認しつつ、線形写像が主な構造を捉えていることを確認

 **このフェーズの意味** : 「モデルごとにバラバラの世界を見ているのではなく、 **座標系が違うだけで見ている“感情地形”はほぼ同じ** 」という強い示唆を得た。小型モデル間でここまできれいにalignできることは、今後のスケーリング研究の足場になる。

---

#### ✅ Phase 4：残差パッチング（感情方向を“注入”してみる）

 **目的** : 見つけた感情方向が、本当に生成テキストの感情トーンを操作できるかを確かめる。

 **やったこと** :

* 中立プロンプトに対して、特定層の残差に

  `residual += α * emotion_vector`

  を適用し、その後の生成文を観察
* α=1.0 付近で明確なスタイル変化（感謝のにじみ、怒りの増加など）を確認
* 一方でαを大きくしすぎると、反復表現や不自然な文が増えることも観測
* 1トークン生成では変化がわかりづらく、10〜30トークン生成することで効果がよりクリアになると判明

 **このフェーズの意味** : 感情ベクトルが単なる解析用のエンベディングではなく、**モデルの振る舞いを変える“操作レバー”である**ことを実験的に確認した重要なステップ。

---

#### ✅ Phase 5：層×αスイープ実験（どの層がどれだけ“効く”のか測る）

 **目的** : どの層でどれくらい感情方向を加えると、最も自然かつ効果的に感情が表出するかを定量的に測る。

 **やったこと** :

* 対象層：Layer 3, 5, 7, 9, 11
* α ∈ {−2, −1, −0.5, 0, 0.5, 1, 2}
* 生成文を
  * sentimentモデル
  * politenessモデル
  * GoEmotionsなどのemotionモデル

    で自動評価
* Layer 9, 11 付近で最も強い効果が得られ、α=0.5〜1.0が「効きすぎず自然さも保つ」レンジであることがわかった
* α=2.0 では崩壊しやすく、感情方向の線形介入には上限があることも確認

 **このフェーズの意味** : 感情回路が「どこで最大化されるか」「どの程度までなら安全にいじれるか」という**チューニングカーブ**が見えてきた。これは将来の制御LLM設計に直結する知見である。

---

#### ✅ Phase 6：HeadスクリーニングとAblation（どのヘッドが“感情に反応しているか”を探す）

 **目的** : 感情語トークンに対して、どのattention headがどれだけ追加の注意を向けているかを測り、候補headを特定する。

 **やったこと** :

* 感情文 vs 中立文で、各headの感情語トークンへのattention差分 Δattention を計算
* Gratitude では Layer 1 Head 10 がΔ≈0.34でトップ、他にも Layer 3 Head 2, Layer 1 Head 11 などが高スコア
* Ablation実験として、Layer 1 Head 10 を無効化し、生成文のsentimentやgratitudeキーワードを比較
  * わずかな変化のみ（分散回路である可能性を示唆）

 **このフェーズの意味** : ここで初めて、「このheadたちが感情処理の**入口**かもしれない」という具体的な当たりがついた。まだ関連性は相関レベルだが、次の因果パッチングへの重要な布石となった。

---

#### ✅ Phase 7：Headパッチング（特定ヘッドが本当に“因果的に効くか”を試す）

 **目的** : Phase 6で見つけた重要headに対して、出力をパッチングし、感情表現に因果的な影響を与えるかどうかを検証する。

 **やったこと** :

* Layer 1 Head 10 を対象に、pattern_v / v_only などのモードでhead出力を差し替え
* 中立プロンプトに対してpatch有無で多数サンプルを生成し、
  * sentimentスコア
  * gratitude関連キーワード出現数

    などを比較
* 一例として、pattern_vモードで
  * sentiment: 0.5832 → 0.5981（+0.0149）
  * gratitudeキーワード: 4 → 8（2倍）

    という変化を確認

 **このフェーズの意味** : 「このheadは感情語に反応している」だけでなく、「 **このheadをいじると感情的な出力が増える** 」という因果的なリンクを示すことに成功した。感情回路研究が“観察の段階”から“介入と制御の段階”へ進んだ瞬間である。

---

#### 🔭 Phase 8（これから）：中規模モデルへのスケーリング（感情回路の“成長”を見る）

 **目的** : 160Mクラスで見つけた構造が、410M〜1.3B〜8Bといった中規模モデルでどう変化・安定化するかを調べる。

 **やること（案）** :

* Pythia 410M, GPT-J, 1.3Bクラスなどを対象に、Phase 1〜7 と同様のpipelineを適用
* 感情ベクトルの分離度、サブスペースoverlap、alignmentのしやすさを比較
* 重要headの層位置や数がスケールとともにどう変わるかをトレース

 **このフェーズがくれるもの** : 「小さな脳で見つかった感情回路が、大きな脳ではどう進化するか」という“成長の物語”。卒論・修論レベルのしっかりしたストーリーになる。

---

#### 🌌 Phase 9（これから）：感情回路の構造的解剖（OV/QKとmulti-head回路）

 **目的** : 単一headではなく、複数head＋MLPを含む回路として感情処理を再構成する。

 **やること（案）** :

* 重要headのOV/QK行列を解析し、「どのトークンから何を読み取り、どのトークンに何を書いているか」を特定
* "感情を拾うhead"、"感情を集約するhead"、"感情を出力に反映するhead" の役割分担を推定
* 複数headを同時にpatch/ablateし、単一headのときとは異なる大きな効果を測定

 **このフェーズがくれるもの** : 「感情回路」が単なる感情ベクトルや1つのheadではなく、**小さなモジュールネットワーク**として存在することを描き出せるようになる。

---

#### 🌍 Phase 10（これから）：多言語・多属性への一般化

 **目的** : 感情回路の構造が英語以外や、感情以外の属性でもどこまで共通するかを探る。

 **やること（案）** :

* 日本語・他言語データセットで同様の感情ベクトル・パッチング実験を行う
* politeness, formality, humor, threat など他の軸に対してもサブスペースと回路を探索
* 言語間・属性間で共通する回路パターン／異なるパターンを整理

 **このフェーズがくれるもの** : 「LLMの中にある“社会性”の回路」の片鱗が見えてくる。人が持つ多様なスタイルや感情が、どれくらい共通構造で支えられているかを知る手がかりになる。

---

#### 🚢 Phase 11（これから）：応用と評価（感情回路を“使ってみる”）

 **目的** : 見つけた回路とベクトルを、実際の生成制御や安全性・表現デザインに生かしてみる。

 **やること（案）** :

* 感情回路を使ったトーン調整エージェント（感謝多め／攻撃性低めなど）のプロトタイプを作る
* 人間評価で、パッチング前後の応答の自然さ・伝達される感情を比較
* alignmentやRLHFと組み合わせ、機械論的制御＋データ駆動制御のハイブリッドの可能性を探る

 **このフェーズがくれるもの** : 研究が「ただの解析」で終わらず、**現実のLLMデザインや運用の指針**に還元される。ここまで来ると、“LLMの中にどんな感情回路を持たせたいか”という設計の議論もできるようになる。

---

ここまでが、感情回路研究の「過去の航海ログ」と「これからの航路図」である。迷ったときは、今どのフェーズにいて、次にどの灯台を目指したいのかを、この一覧に照らして確かめればよい。

### 5. 出口と応用

* 感情表現の因果解析と構造理解の手法として、他の属性（truthfulness, bias, persona）にも拡張可能
* モデルの倫理的制御、感情調整チャットボット、表現バイアス除去などの応用
* LLM alignment技術へのブリッジとして、機械論的視点からの貢献

---

### 6. 自分と研究

この研究は、機械が人と同じように感情を持つのか？という哲学的な問いから始まった。今は、"持つ"のではなく、**"感情的な応答を生み出す構造があるのか"**を確かめようとしている。

研究の道中では迷うこともある。でもそのたびに立ち返れる原点がある。

この問いを追いかけていること自体が、もう私にとっては喜びだ。

#### 6.1 この研究の「好きなところ」

振り返ってみると、このプロジェクトには自分でも気に入っている点がいくつかある。

* **小さい世界を徹底的に理解しようとしているところ**

  3モデル×4感情という、決して大規模ではない設定から始めている。でもその代わりに、観察→因果→構造→アライメント→回路という一連の流れを、一度きちんと最後まで歩き切ろうとしている。その態度そのものに価値があると感じている。
* **失敗を「やり直し」ではなく「問いの深化」として扱っているところ**

  類似度が0だったり、期待どおりに差が出なかったりしたフェーズもあった。それを単に消すのではなく、「文末が悪いのか？」「サブスペースで見るべきか？」「座標系を合わせればどうか？」という次の問いに変えてきた。このプロセスは、今後も研究を続けていく上での自分のスタイルになっていくはずだ。
* **技術と素朴な好奇心がちゃんとつながっているところ**

  Multi-token patching や MLflow、統計検定など、技術的にはそれなりに込み入ったことをしている。でも根っこにあるのは「感謝されたとき、このモデルの中で何が起きているんだろう？」という素朴な好奇心だ。そのギャップを自分の手で埋めていく感覚が楽しい。

このマスタープランは、そうした好奇心と技術と失敗の記録をまとめた「航海図」でもある。今後、さらに大きなモデルや多言語に挑戦していく中で、迷ったり立ち止まったりしたときには、ここに戻って「自分はなぜこの旅を始めたのか」を思い出すための場所にしたい。
