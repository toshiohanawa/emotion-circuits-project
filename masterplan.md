## Emotion Circuits Master Plan

### 1. ビジョンと出発点

機械は感情をどう扱っているのか？この疑問は、LLMの応答からにじみ出るトーンや雰囲気、微妙な礼儀や共感性に気づいたときに芽生えた。ある大学教員の「LLMの入出力しか見えないのは人と同じだよね」という言葉は、この問いをさらに深めるきっかけとなった。

しかし、人間は感情を「感じて」から「表現する」までに、内的な状態の変化と、その影響による応答の変化がある。もしLLMにも似たような流れがあるなら、感情はどこで取り込まれ、どこを通り、どこで出力に関与するのだろう？

この研究は、Transformerモデル内部での"感情の流れ"を、ベクトルとして、回路として、構造として探る試みである。

---

### 2. 核心となる問い

* 感情的な入力は、どの層・どのhead・どの残差空間に影響を与えるのか？
* その影響はどのように伝播し、どのモジュールが読み出すのか？
* 感情が残差方向やattention headを通じて、どのように出力のスタイルに現れるのか？
* この"感情回路"はモデル間やモデル規模によって安定して存在するのか？
* 因果的な介入（patching, ablation）によってこの流れを操作できるか？

---

### 3. 技術的アプローチ

この研究は「書き込み → 伝搬 → 読み出し → 出力影響」の4ステップ構造に基づく：

1. 書き込み点探索：感情語トークンに対するattention分布と残差方向の活性
2. 伝播経路の観察：各層のresidual streamの変化をトレース
3. 読み出し部位の特定：late layerのheadやMLPがどの方向を読むかを因果的に分析
4. 出力への効果：感情表現のある/なしで出力文のスタイルやスコアがどう変わるか

この構造は、小型モデル（GPT-2 124M, Pythia 160Mなど）をベースに着実に確認されてきた。

今後はこれを中規模（410M, 1.3B）、さらには8Bクラスまで拡張し、感情回路がどう拡大・分散・安定化していくかを明らかにしていく。

---

### 4. フェーズ別ロードマップ

ここでは、この研究を **航海日誌と未来の航路図** の両方として整理する。

すでに完了したフェーズは「どこまで来たか」を、これからのフェーズは「どこへ向かうか」を示す。

---

#### ✅ Phase 0：観測装置の構築（環境と道具をそろえる）

 **目的** : LLMの内部状態（活性）を安全かつ再現性高く観測できる「望遠鏡」をつくる。

 **やったこと** :

* Hugging Face Transformers と独自ラッパを用いて、GPT-2 / Pythia / GPT-Neo の
  * 残差ストリーム
  * MLP出力
  * attention重み（必要に応じて）

    をフックできるインフラを整備
* 実験プロファイル（baseline / extended）や結果保存パスを一元管理する `ProjectContext` を設計
* MLflow やファイル構造を整え、「同じ実験を何度でも再現できる」状態にした

 **このフェーズの意味** : ここで、単なるプロンプト遊びから一歩進み、「LLMの中身を計測する研究者の視点」を手に入れた。

---

#### ✅ Phase 1：感情データセット構築（感情の“試験紙”をつくる）

 **目的** : 感情回路を刺激するための、ノイズの少ない・バランスの取れた感情文セットをつくる。

 **やったこと** :

* 感謝 / 怒り / 謝罪 / 中立 の4感情について、短くはっきりした英語文を合計680文作成
  * Baseline: 各70文
  * Extended: 各100文
* GPT-2トークナイザでトークン長を確認し、平均約7トークンという「扱いやすい長さ」に調整
* 感情語（thank, sorry, angry など）が明示的に含まれるよう配慮し、後続の token-based 解析の土台をつくった

 **このフェーズの意味** : 感情回路を観測するための「テストベンチ」を手作りした。ここから先の全フェーズは、この試験紙にモデルを浸して色の変化を観察する営みと言える。

---

#### ✅ Phase 2：活性抽出（感情刺激に対する“脳波”を記録する）

 **目的** : 感情文を入力したとき、各層・各トークンでどのような活性が生じるかを網羅的に記録する。

 **やったこと** :

* GPT-2 / Pythia-160M / GPT-Neo-125M それぞれについて、全12層の
  * 残差ストリーム
  * MLP出力

    を全サンプル・全トークンに対して保存
* 形状 `[n_layers][n_samples][seq_len, d_model]` のテンソルとして整備し、約431MBの「感情脳波ログ」を作成
* 実行時ログやMLflowと紐づけ、どのrunがどの活性ファイルに対応するかを追跡可能にした

 **このフェーズの意味** : 以降のすべての解析（ベクトル構築、サブスペース、パッチング、head解析）の“生データ”がここで揃った。

---

#### ✅ Phase 3：感情ベクトル構築（感情の“方向”を見つける）

 **目的** : 「この方向に進むと感謝が強くなる」「この方向に進むと怒りが強くなる」といった、感情の線形方向を同定する。

 **やったこと** :

* 2種類の感情ベクトルを構築
  * sentence-end ベクトル：文章末トークンの残差を平均
  * token-based ベクトル：感情語トークン位置の残差を平均
* Gratitude vs Anger のcos類似度を比較
  * sentence-end: 約0.37
  * token-based: 約0.16（より明確に分離）
* 層ごとのL1/L2ノルムを解析し、Layer 9〜11で感情成分が最も強くなることを確認

 **このフェーズの意味** : 「感情は残差空間のどこかに存在する」はず、という仮説に対して、「確かにこの方向がそれらしい」という証拠を得たフェーズ。ここで初めて“感情ベクトル”という操作可能なオブジェクトを手にした。

---

#### ✅ Phase 3.5：サブスペース解析とアライメント（モデル間で“感情の地形”を比べる）

 **目的** : モデルごとに感情サブスペースを求め、それらがどの程度似ているか／線形写像でどこまで揃うかを調べる。

 **やったこと** :

* 各モデルで感情ベクトル集合にPCAを適用し、k=10の感情サブスペースを抽出
* GPT-2 ↔ Pythia-160M ↔ GPT-Neo-125M のサブスペースoverlapを計算
  * いずれの組み合わせも ≈0.14〜0.15 で、ランダム基準より明確に高い
* Neutral alignment（中立文に基づく線形写像）を学習し、
  * 整列前のcos² ≈ 0.001
  * 整列後のcos² ≈ 0.99 を達成
* Procrustes alignmentでも改善を確認しつつ、線形写像が主な構造を捉えていることを確認

 **このフェーズの意味** : 「モデルごとにバラバラの世界を見ているのではなく、 **座標系が違うだけで見ている“感情地形”はほぼ同じ** 」という強い示唆を得た。小型モデル間でここまできれいにalignできることは、今後のスケーリング研究の足場になる。

---

#### ✅ Phase 4：残差パッチング（感情方向を“注入”してみる）

 **目的** : 見つけた感情方向が、本当に生成テキストの感情トーンを操作できるかを確かめる。

 **やったこと** :

* 中立プロンプトに対して、特定層の残差に

  `residual += α * emotion_vector`

  を適用し、その後の生成文を観察
* α=1.0 付近で明確なスタイル変化（感謝のにじみ、怒りの増加など）を確認
* 一方でαを大きくしすぎると、反復表現や不自然な文が増えることも観測
* 1トークン生成では変化がわかりづらく、10〜30トークン生成することで効果がよりクリアになると判明

 **このフェーズの意味** : 感情ベクトルが単なる解析用のエンベディングではなく、**モデルの振る舞いを変える“操作レバー”である**ことを実験的に確認した重要なステップ。

---

#### ✅ Phase 5：層×αスイープ実験（どの層がどれだけ“効く”のか測る）

 **目的** : どの層でどれくらい感情方向を加えると、最も自然かつ効果的に感情が表出するかを定量的に測る。

 **やったこと** :

* 対象層：Layer 3, 5, 7, 9, 11
* α ∈ {−2, −1, −0.5, 0, 0.5, 1, 2}
* 生成文を
  * sentimentモデル
  * politenessモデル
  * GoEmotionsなどのemotionモデル

    で自動評価
* Layer 9, 11 付近で最も強い効果が得られ、α=0.5〜1.0が「効きすぎず自然さも保つ」レンジであることがわかった
* α=2.0 では崩壊しやすく、感情方向の線形介入には上限があることも確認

 **このフェーズの意味** : 感情回路が「どこで最大化されるか」「どの程度までなら安全にいじれるか」という**チューニングカーブ**が見えてきた。これは将来の制御LLM設計に直結する知見である。

---

#### ✅ Phase 6：HeadスクリーニングとAblation（どのヘッドが“感情に反応しているか”を探す）

 **目的** : 感情語トークンに対して、どのattention headがどれだけ追加の注意を向けているかを測り、候補headを特定する。

 **やったこと** :

* 感情文 vs 中立文で、各headの感情語トークンへのattention差分 Δattention を計算
* Gratitude では Layer 1 Head 10 がΔ≈0.34でトップ、他にも Layer 3 Head 2, Layer 1 Head 11 などが高スコア
* Ablation実験として、Layer 1 Head 10 を無効化し、生成文のsentimentやgratitudeキーワードを比較
  * わずかな変化のみ（分散回路である可能性を示唆）

 **このフェーズの意味** : ここで初めて、「このheadたちが感情処理の**入口**かもしれない」という具体的な当たりがついた。まだ関連性は相関レベルだが、次の因果パッチングへの重要な布石となった。

---

#### ✅ Phase 7：Headパッチング（特定ヘッドが本当に“因果的に効くか”を試す）

 **目的** : Phase 6で見つけた重要headに対して、出力をパッチングし、感情表現に因果的な影響を与えるかどうかを検証する。

 **やったこと** :

* Layer 1 Head 10 を対象に、pattern_v / v_only などのモードでhead出力を差し替え
* 中立プロンプトに対してpatch有無で多数サンプルを生成し、
  * sentimentスコア
  * gratitude関連キーワード出現数

    などを比較
* 一例として、pattern_vモードで
  * sentiment: 0.5832 → 0.5981（+0.0149）
  * gratitudeキーワード: 4 → 8（2倍）

    という変化を確認

 **このフェーズの意味** : 「このheadは感情語に反応している」だけでなく、「 **このheadをいじると感情的な出力が増える** 」という因果的なリンクを示すことに成功した。感情回路研究が“観察の段階”から“介入と制御の段階”へ進んだ瞬間である。

---

#### 🔭 Phase 8（これから）：中規模モデルへのスケーリング（感情回路の“成長”を見る）

 **目的** : 160Mクラスで見つけた構造が、410M〜1.3B〜8Bといった中規模モデルでどう変化・安定化するかを調べる。

 **やること（案）** :

* Pythia 410M, GPT-J, 1.3Bクラスなどを対象に、Phase 1〜7 と同様のpipelineを適用
* 感情ベクトルの分離度、サブスペースoverlap、alignmentのしやすさを比較
* 重要headの層位置や数がスケールとともにどう変わるかをトレース

 **このフェーズがくれるもの** : 「小さな脳で見つかった感情回路が、大きな脳ではどう進化するか」という“成長の物語”。卒論・修論レベルのしっかりしたストーリーになる。

---

#### 🌌 Phase 9（これから）：感情回路の構造的解剖（OV/QKとmulti-head回路）

 **目的** : 単一headではなく、複数head＋MLPを含む回路として感情処理を再構成する。

 **やること（案）** :

* 重要headのOV/QK行列を解析し、「どのトークンから何を読み取り、どのトークンに何を書いているか」を特定
* "感情を拾うhead"、"感情を集約するhead"、"感情を出力に反映するhead" の役割分担を推定
* 複数headを同時にpatch/ablateし、単一headのときとは異なる大きな効果を測定

 **このフェーズがくれるもの** : 「感情回路」が単なる感情ベクトルや1つのheadではなく、**小さなモジュールネットワーク**として存在することを描き出せるようになる。

---

#### 🌍 Phase 10（これから）：多言語・多属性への一般化

 **目的** : 感情回路の構造が英語以外や、感情以外の属性でもどこまで共通するかを探る。

 **やること（案）** :

* 日本語・他言語データセットで同様の感情ベクトル・パッチング実験を行う
* politeness, formality, humor, threat など他の軸に対してもサブスペースと回路を探索
* 言語間・属性間で共通する回路パターン／異なるパターンを整理

 **このフェーズがくれるもの** : 「LLMの中にある“社会性”の回路」の片鱗が見えてくる。人が持つ多様なスタイルや感情が、どれくらい共通構造で支えられているかを知る手がかりになる。

---

#### 🚢 Phase 11（これから）：応用と評価（感情回路を“使ってみる”）

 **目的** : 見つけた回路とベクトルを、実際の生成制御や安全性・表現デザインに生かしてみる。

 **やること（案）** :

* 感情回路を使ったトーン調整エージェント（感謝多め／攻撃性低めなど）のプロトタイプを作る
* 人間評価で、パッチング前後の応答の自然さ・伝達される感情を比較
* alignmentやRLHFと組み合わせ、機械論的制御＋データ駆動制御のハイブリッドの可能性を探る

 **このフェーズがくれるもの** : 研究が「ただの解析」で終わらず、**現実のLLMデザインや運用の指針**に還元される。ここまで来ると、“LLMの中にどんな感情回路を持たせたいか”という設計の議論もできるようになる。

---

ここまでが、感情回路研究の「過去の航海ログ」と「これからの航路図」である。迷ったときは、今どのフェーズにいて、次にどの灯台を目指したいのかを、この一覧に照らして確かめればよい。

### 5. 出口と応用

* 感情表現の因果解析と構造理解の手法として、他の属性（truthfulness, bias, persona）にも拡張可能
* モデルの倫理的制御、感情調整チャットボット、表現バイアス除去などの応用
* LLM alignment技術へのブリッジとして、機械論的視点からの貢献

---

### 6. 自分と研究

この研究は、機械が人と同じように感情を持つのか？という哲学的な問いから始まった。今は、"持つ"のではなく、**"感情的な応答を生み出す構造があるのか"**を確かめようとしている。

研究の道中では迷うこともある。でもそのたびに立ち返れる原点がある。

この問いを追いかけていること自体が、もう私にとっては喜びだ。
