{"run_id": "bc0044bd-e7db-434b-9ce5-880dc695d6d0", "timestamp": "2025-11-19T08:40:59.465645+00:00", "phase": "phase2", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cpu", "elapsed_seconds": 14.08, "samples": 4, "metadata": {"layers": [0], "hook_pos": "both", "batch_size": 1, "max_samples_per_emotion": 1, "output_path": "results/baseline_smoke/activations/gpt2_small.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--layers", "0", "--max-samples-per-emotion", "1", "--batch-size", "1", "--device", "cpu"]}
{"run_id": "6af6fc53-64a0-4e26-b877-cb00d8ed1dc4", "timestamp": "2025-11-19T08:41:09.571495+00:00", "phase": "phase2", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cpu", "elapsed_seconds": 1.88, "samples": 4, "metadata": {"layers": [0], "hook_pos": "both", "batch_size": 1, "max_samples_per_emotion": 1, "output_path": "results/baseline_smoke/activations/gpt2_small.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--layers", "0", "--max-samples-per-emotion", "1", "--batch-size", "1", "--device", "cpu"]}
{"run_id": "f0664994-720b-49d8-8b53-a221db50c6a3", "timestamp": "2025-11-19T08:50:16.036937+00:00", "phase": "phase1_dataset", "profile": "baseline_smoke", "model": null, "device": null, "elapsed_seconds": 0.0, "samples": 20, "metadata": {"emotion_counts": {"gratitude": 5, "anger": 5, "apology": 5, "neutral": 5}, "input_path": "data/emotion_dataset_smoke.jsonl", "output_path": "data/emotion_dataset_smoke.jsonl", "text_field": "text", "label_field": "label", "prefer_prompts": false}, "cli_args": ["--profile", "baseline_smoke", "--input", "data/emotion_dataset_smoke.jsonl"]}
{"run_id": "f3aafdc3-6e12-4bfb-89de-dfe5bd928526", "timestamp": "2025-11-19T08:50:30.692449+00:00", "phase": "phase2", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cuda", "elapsed_seconds": 2.15, "samples": 12, "metadata": {"layers": [0, 6], "hook_pos": "both", "batch_size": 8, "max_samples_per_emotion": 3, "output_path": "results/baseline_smoke/activations/gpt2_small.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--layers", "0", "6", "--max-samples-per-emotion", "3", "--device", "cuda", "--batch-size", "8"]}
{"run_id": "a8c5d507-be8d-4c87-8063-f3d29e839e09", "timestamp": "2025-11-19T08:50:35.888444+00:00", "phase": "phase3", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cuda", "elapsed_seconds": 0.29, "samples": 12, "metadata": {"n_components": 3, "use_torch": true, "layer_count": 2, "activation_path": "results/baseline_smoke/activations/gpt2_small.pkl", "vector_output": "results/baseline_smoke/emotion_vectors/gpt2_small_vectors_token_based.pkl", "subspace_output": "results/baseline_smoke/emotion_subspaces/gpt2_small_subspaces.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--n-components", "3", "--use-torch", "--device", "cuda"]}
{"run_id": "1a66a97b-6916-4ad3-b4f6-999c75b4364a", "timestamp": "2025-11-19T08:50:40.267028+00:00", "phase": "phase4", "profile": "baseline_smoke", "model": "gpt2_small_vs_gpt2_small", "device": "cuda", "elapsed_seconds": 0.32, "samples": 2, "metadata": {"k_max": 3, "use_torch": true, "layer_count": 2, "result_count": 18, "output_path": "results/baseline_smoke/alignment/gpt2_small_vs_gpt2_small_token_based_full.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model-a", "gpt2_small", "--model-b", "gpt2_small", "--k-max", "3", "--use-torch", "--device", "cuda"]}
{"run_id": "a2fc6ddb-9e70-4b54-813e-96787ead59df", "timestamp": "2025-11-19T08:50:53.495755+00:00", "phase": "phase5", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cuda", "elapsed_seconds": 4.64, "samples": 3, "metadata": {"layers": [0, 6], "patch_window": 3, "sequence_length": 20, "alpha": 0.8, "batch_size": 4, "random_control": false, "num_random": 0, "result_path": "results/baseline_smoke/patching/residual/gpt2_small_residual_sweep.pkl", "random_result_path": null}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--layers", "0", "6", "--patch-window", "3", "--sequence-length", "20", "--alpha", "0.8", "--max-samples-per-emotion", "3", "--device", "cuda", "--batch-size", "4"]}
{"run_id": "b15bb006-4b3e-4ebc-afd7-59709ceb07b3", "timestamp": "2025-11-19T08:51:08.762959+00:00", "phase": "phase6_head_screening", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cuda", "elapsed_seconds": 8.23, "samples": 3, "metadata": {"layers": [0, 1], "sequence_length": 20, "batch_size": 4, "output_path": "results/baseline_smoke/screening/head_scores_gpt2_small.json"}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--layers", "0", "1", "--max-samples", "3", "--sequence-length", "20", "--device", "cuda", "--batch-size", "4"]}
{"run_id": "6c7209db-4480-4da5-aacd-007178000737", "timestamp": "2025-11-19T08:51:20.885990+00:00", "phase": "phase6_head_patching", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cuda", "elapsed_seconds": 3.03, "samples": 3, "metadata": {"heads": [[0, 0]], "sequence_length": 20, "batch_size": 4, "output_path": "results/baseline_smoke/patching/head_patching/gpt2_small_head_ablation.pkl", "max_samples": 3}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--heads", "0:0", "--max-samples", "3", "--sequence-length", "20", "--device", "cuda", "--batch-size", "4"]}
{"run_id": "9b7d57e9-13e8-440c-94d4-9178880bce5e", "timestamp": "2025-11-19T08:52:10.076800+00:00", "phase": "phase7_statistics", "profile": "baseline_smoke", "model": null, "device": "cpu", "elapsed_seconds": 23.88, "samples": null, "metadata": {"mode": "effect", "phase_filter": "residual,head", "n_bootstrap": 2000, "n_jobs": 1, "alpha": 0.05, "power_target": 0.8, "effect_targets": [0.2, 0.3, 0.5], "output_dir": "results/baseline_smoke/statistics"}, "cli_args": ["--profile", "baseline_smoke", "--mode", "effect", "--phase-filter", "residual,head"]}
{"run_id": "c36647c6-7cab-40c3-bdf9-f433c3af0a5c", "timestamp": "2025-11-19T08:52:23.837170+00:00", "phase": "phase2", "profile": "baseline_smoke", "model": "llama3_8b", "device": "cuda", "elapsed_seconds": 4.66, "samples": 4, "metadata": {"layers": [0, 1, 2], "hook_pos": "both", "batch_size": 4, "max_samples_per_emotion": 1, "output_path": "results/baseline_smoke/activations/llama3_8b.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "llama3_8b", "--layers", "0", "1", "2", "--max-samples-per-emotion", "1", "--device", "cuda", "--batch-size", "4"]}
{"run_id": "72e0c4f7-d41b-4bb8-8f79-d1a589a2b5e7", "timestamp": "2025-11-19T08:52:31.400917+00:00", "phase": "phase3", "profile": "baseline_smoke", "model": "llama3_8b", "device": "cuda", "elapsed_seconds": 0.31, "samples": 4, "metadata": {"n_components": 3, "use_torch": true, "layer_count": 3, "activation_path": "results/baseline_smoke/activations/llama3_8b.pkl", "vector_output": "results/baseline_smoke/emotion_vectors/llama3_8b_vectors_token_based.pkl", "subspace_output": "results/baseline_smoke/emotion_subspaces/llama3_8b_subspaces.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "llama3_8b", "--n-components", "3", "--use-torch", "--device", "cuda"]}
{"run_id": "59d49676-b0e8-4341-a57a-69de1bd2fe3d", "timestamp": "2025-11-19T08:52:50.153075+00:00", "phase": "phase5", "profile": "baseline_smoke", "model": "llama3_8b", "device": "cuda", "elapsed_seconds": 6.01, "samples": 1, "metadata": {"layers": [0, 1], "patch_window": 3, "sequence_length": 20, "alpha": 0.8, "batch_size": 2, "random_control": false, "num_random": 0, "result_path": "results/baseline_smoke/patching/residual/llama3_8b_residual_sweep.pkl", "random_result_path": null}, "cli_args": ["--profile", "baseline_smoke", "--model", "llama3_8b", "--layers", "0", "1", "--patch-window", "3", "--sequence-length", "20", "--alpha", "0.8", "--max-samples-per-emotion", "1", "--device", "cuda", "--batch-size", "2"]}
{"run_id": "55b11a86-3d28-45cf-aa92-c206044cc1c1", "timestamp": "2025-11-19T08:53:15.136008+00:00", "phase": "phase2", "profile": "baseline_smoke", "model": "gpt2_small", "device": "cpu", "elapsed_seconds": 1.74, "samples": 4, "metadata": {"layers": [0], "hook_pos": "both", "batch_size": 4, "max_samples_per_emotion": 1, "output_path": "results/baseline_smoke/activations/gpt2_small.pkl"}, "cli_args": ["--profile", "baseline_smoke", "--model", "gpt2_small", "--layers", "0", "--max-samples-per-emotion", "1", "--device", "cpu", "--batch-size", "4"]}
